{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LITHUVARSHNI/EI-Teique/blob/main/EI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ML Algorithms for Predictive Analysis"
      ],
      "metadata": {
        "id": "8Q9ziKMi5vE7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qn9rzMVh24Fb"
      },
      "source": [
        "Linear Regression\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7N0-GMVZRyS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a9ace0b-df09-4d07-a04d-6f45eadac3e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error - Well-Being: 1.2874209973206912e-28\n",
            "Mean Squared Error - Sociality: 7.204929601018574e-29\n",
            "Mean Squared Error - Emotionality: 8.835242138475332e-29\n",
            "Mean Squared Error - Self-Control: 1.861711736321588e-29\n",
            "[18. 20. 12. 26. 27. 33. 25. 17. 24. 29. 27. 16. 35. 27. 24. 23. 29. 28.\n",
            " 20. 30. 21. 36. 28. 33. 21. 16. 37. 36. 30. 18.]\n",
            "[13. 17. 12. 30. 29. 24. 28. 21. 36. 31. 36. 20. 21. 36. 27. 17. 20. 21.\n",
            " 27. 33. 27. 29. 33. 20. 26. 31. 31. 24. 30. 28.]\n",
            "[18. 15. 15. 17. 25. 21.  9. 17. 27. 26. 24. 11. 20. 22. 24. 15. 23. 29.\n",
            " 19. 27. 21. 25. 22. 34. 23. 24. 30. 27. 23. 20.]\n",
            "[17. 14. 15. 19. 28. 36. 24. 13. 22. 30. 28. 28. 27. 21. 27. 22. 31. 30.\n",
            " 26. 22. 27. 29. 39. 31. 28. 22. 34. 42. 26. 34.]\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.impute import SimpleImputer\n",
        "# Load your dataset (replace 'your_dataset.csv' with the actual file path)\n",
        "data = pd.read_csv('/samp_file.csv')\n",
        "# Assuming your dataset has columns 'Q1' to 'Q40' for the 40 questionnaire responses\n",
        "# For each category, X represents the features (questionnaire responses)\n",
        "X_well_being = data[['wb_q1','wb_q2','wb_q3','wb_q4','wb_q5','wb_q6','wb_q7','wb_q8','wb_q9','wb_10']]  # Replace ... with the actual column names\n",
        "X_sociality = data[['soc_q1','soc_q2','soc_q3','soc_q4','soc_q5','soc_q6','soc_q7','soc_q8','soc_q9','soc_q10']]  # Replace ... with the actual column names\n",
        "X_emotionality = data[['emo_q1','emo_q2','emo_q3','emo_q4','emo_q5','emo_q6','emo_q7','emo_q8','emo_q9','emo_q10']]  # Replace ... with the actual column names\n",
        "X_self_control = data[['sc_q1','sc_q2','sc_q3','sc_q4','sc_q5','sc_q6','sc_q7','sc_q8','sc_q9','sc_q10']]  # Replace ... with the actual column names\n",
        "# Y represents the target variables for each category (the final numerical values)\n",
        "Y_well_being = data['Final Well-Being Value']\n",
        "Y_sociality = data['Final Sociality Value']\n",
        "Y_emotionality = data['Final Emotionality Value']\n",
        "Y_self_control = data['Final Self-Control Value']\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_well_being = imputer.fit_transform(X_well_being)\n",
        "X_sociality = imputer.fit_transform(X_sociality)\n",
        "X_emotionality = imputer.fit_transform(X_emotionality)\n",
        "X_self_control = imputer.fit_transform(X_self_control)\n",
        "# Split each category's data into training and testing sets\n",
        "X_wb_train, X_wb_test, Y_wb_train, Y_wb_test = train_test_split(X_well_being, Y_well_being, test_size=0.2, random_state=42)\n",
        "X_so_train, X_so_test, Y_so_train, Y_so_test = train_test_split(X_sociality, Y_sociality, test_size=0.2, random_state=42)\n",
        "X_em_train, X_em_test, Y_em_train, Y_em_test = train_test_split(X_emotionality, Y_emotionality, test_size=0.2, random_state=42)\n",
        "X_sc_train, X_sc_test, Y_sc_train, Y_sc_test = train_test_split(X_self_control, Y_self_control, test_size=0.2, random_state=42)\n",
        "# Create Linear Regression models for each category\n",
        "model_well_being = LinearRegression()\n",
        "model_sociality = LinearRegression()\n",
        "model_emotionality = LinearRegression()\n",
        "model_self_control = LinearRegression()\n",
        "# Fit each model to its respective training data\n",
        "model_well_being.fit(X_wb_train, Y_wb_train)\n",
        "model_sociality.fit(X_so_train, Y_so_train)\n",
        "model_emotionality.fit(X_em_train, Y_em_train)\n",
        "model_self_control.fit(X_sc_train, Y_sc_train)\n",
        "# Predict the final numerical values for each category using the respective models\n",
        "Y_wb_pred = model_well_being.predict(X_wb_test)\n",
        "Y_so_pred = model_sociality.predict(X_so_test)\n",
        "Y_em_pred = model_emotionality.predict(X_em_test)\n",
        "Y_sc_pred = model_self_control.predict(X_sc_test)\n",
        "# Calculate the Mean Squared Error (MSE) for each category to evaluate the models' performance\n",
        "mse_well_being = mean_squared_error(Y_wb_test, Y_wb_pred)\n",
        "mse_sociality = mean_squared_error(Y_so_test, Y_so_pred)\n",
        "mse_emotionality = mean_squared_error(Y_em_test, Y_em_pred)\n",
        "mse_self_control = mean_squared_error(Y_sc_test, Y_sc_pred)\n",
        "print(f\"Mean Squared Error - Well-Being: {mse_well_being}\")\n",
        "print(f\"Mean Squared Error - Sociality: {mse_sociality}\")\n",
        "print(f\"Mean Squared Error - Emotionality: {mse_emotionality}\")\n",
        "print(f\"Mean Squared Error - Self-Control: {mse_self_control}\")\n",
        "\n",
        "print(Y_wb_pred)\n",
        "print(Y_so_pred )\n",
        "print(Y_em_pred)\n",
        "print(Y_sc_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear Regression .Ridge,Lasso,Stacked Model"
      ],
      "metadata": {
        "id": "aZXfJGaAyMQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Load your dataset (replace 'your_dataset.csv' with the actual file path)\n",
        "data = pd.read_csv('duplicate1.csv')\n",
        "\n",
        "# Assuming your dataset has columns 'Q1' to 'Q40' for the 40 questionnaire responses\n",
        "# For each category, X represents the features (questionnaire responses)\n",
        "X_well_being = data[['wb_q1','wb_q2','wb_q3','wb_q4','wb_q5','wb_q6','wb_q7','wb_q8','wb_q9','wb_10']]\n",
        "X_sociality = data[['soc_q1','soc_q2','soc_q3','soc_q4','soc_q5','soc_q6','soc_q7','soc_q8','soc_q9','soc_q10']]\n",
        "X_emotionality = data[['emo_q1','emo_q2','emo_q3','emo_q4','emo_q5','emo_q6','emo_q7','emo_q8','emo_q9','emo_q10']]\n",
        "X_self_control = data[['sc_q1','sc_q2','sc_q3','sc_q4','sc_q5','sc_q6','sc_q7','sc_q8','sc_q9','sc_q10']]\n",
        "\n",
        "# Y represents the target variables for each category (the final numerical values)\n",
        "Y_well_being = data['Final Well-Being Value']\n",
        "Y_sociality = data['Final Sociality Value']\n",
        "Y_emotionality = data['Final Emotionality Value']\n",
        "Y_self_control = data['Final Self-Control Value']\n",
        "\n",
        "# Impute missing values with the mean for each category's features\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_well_being = imputer.fit_transform(X_well_being)\n",
        "X_sociality = imputer.fit_transform(X_sociality)\n",
        "X_emotionality = imputer.fit_transform(X_emotionality)\n",
        "X_self_control = imputer.fit_transform(X_self_control)\n",
        "\n",
        "# Split each category's data into training and testing sets\n",
        "X_wb_train, X_wb_test, Y_wb_train, Y_wb_test = train_test_split(X_well_being, Y_well_being, test_size=0.2, random_state=42)\n",
        "X_so_train, X_so_test, Y_so_train, Y_so_test = train_test_split(X_sociality, Y_sociality, test_size=0.2, random_state=42)\n",
        "X_em_train, X_em_test, Y_em_train, Y_em_test = train_test_split(X_emotionality, Y_emotionality, test_size=0.2, random_state=42)\n",
        "X_sc_train, X_sc_test, Y_sc_train, Y_sc_test = train_test_split(X_self_control, Y_self_control, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create Linear Regression models for each category\n",
        "linear_model_well_being = LinearRegression()\n",
        "linear_model_sociality = LinearRegression()\n",
        "linear_model_emotionality = LinearRegression()\n",
        "linear_model_self_control = LinearRegression()\n",
        "\n",
        "# Fit each linear model to its respective training data\n",
        "linear_model_well_being.fit(X_wb_train, Y_wb_train)\n",
        "linear_model_sociality.fit(X_so_train, Y_so_train)\n",
        "linear_model_emotionality.fit(X_em_train, Y_em_train)\n",
        "linear_model_self_control.fit(X_sc_train, Y_sc_train)\n",
        "\n",
        "# Predict the final numerical values for each category using the respective linear models\n",
        "Y_wb_linear_pred = linear_model_well_being.predict(X_wb_test)\n",
        "Y_so_linear_pred = linear_model_sociality.predict(X_so_test)\n",
        "Y_em_linear_pred = linear_model_emotionality.predict(X_em_test)\n",
        "Y_sc_linear_pred = linear_model_self_control.predict(X_sc_test)\n",
        "\n",
        "# Create Ridge and Lasso regression models\n",
        "ridge_model_well_being = Ridge(alpha=1.0)\n",
        "ridge_model_sociality = Ridge(alpha=1.0)\n",
        "ridge_model_emotionality = Ridge(alpha=1.0)\n",
        "ridge_model_self_control = Ridge(alpha=1.0)\n",
        "\n",
        "lasso_model_well_being = Lasso(alpha=1.0)\n",
        "lasso_model_sociality = Lasso(alpha=1.0)\n",
        "lasso_model_emotionality = Lasso(alpha=1.0)\n",
        "lasso_model_self_control = Lasso(alpha=1.0)\n",
        "\n",
        "# Fit Ridge and Lasso models to their respective training data\n",
        "ridge_model_well_being.fit(X_wb_train, Y_wb_train)\n",
        "ridge_model_sociality.fit(X_so_train, Y_so_train)\n",
        "ridge_model_emotionality.fit(X_em_train, Y_em_train)\n",
        "ridge_model_self_control.fit(X_sc_train, Y_sc_train)\n",
        "\n",
        "lasso_model_well_being.fit(X_wb_train, Y_wb_train)\n",
        "lasso_model_sociality.fit(X_so_train, Y_so_train)\n",
        "lasso_model_emotionality.fit(X_em_train, Y_em_train)\n",
        "lasso_model_self_control.fit(X_sc_train, Y_sc_train)\n",
        "\n",
        "# Predict the final numerical values using Ridge and Lasso models\n",
        "Y_wb_ridge_pred = ridge_model_well_being.predict(X_wb_test)\n",
        "Y_so_ridge_pred = ridge_model_sociality.predict(X_so_test)\n",
        "Y_em_ridge_pred = ridge_model_emotionality.predict(X_em_test)\n",
        "Y_sc_ridge_pred = ridge_model_self_control.predict(X_sc_test)\n",
        "\n",
        "Y_wb_lasso_pred = lasso_model_well_being.predict(X_wb_test)\n",
        "Y_so_lasso_pred = lasso_model_sociality.predict(X_so_test)\n",
        "Y_em_lasso_pred = lasso_model_emotionality.predict(X_em_test)\n",
        "Y_sc_lasso_pred = lasso_model_self_control.predict(X_sc_test)\n",
        "\n",
        "# Stack the models (Linear, Ridge, and Lasso)\n",
        "estimators = [\n",
        "    ('linear', linear_model_well_being),\n",
        "    ('ridge', ridge_model_well_being),\n",
        "    ('lasso', lasso_model_well_being)\n",
        "]\n",
        "\n",
        "stacked_model_well_being = StackingRegressor(estimators=estimators, final_estimator=LinearRegression())\n",
        "stacked_model_sociality = StackingRegressor(estimators=estimators, final_estimator=LinearRegression())\n",
        "stacked_model_emotionality = StackingRegressor(estimators=estimators, final_estimator=LinearRegression())\n",
        "stacked_model_self_control = StackingRegressor(estimators=estimators, final_estimator=LinearRegression())\n",
        "\n",
        "# Fit the stacked models\n",
        "stacked_model_well_being.fit(X_wb_train, Y_wb_train)\n",
        "stacked_model_sociality.fit(X_so_train, Y_so_train)\n",
        "stacked_model_emotionality.fit(X_em_train, Y_em_train)\n",
        "stacked_model_self_control.fit(X_sc_train, Y_sc_train)\n",
        "\n",
        "# Predict the final numerical values using stacked models\n",
        "Y_wb_stacked_pred = stacked_model_well_being.predict(X_wb_test)\n",
        "Y_so_stacked_pred = stacked_model_sociality.predict(X_so_test)\n",
        "Y_em_stacked_pred = stacked_model_emotionality.predict(X_em_test)\n",
        "Y_sc_stacked_pred = stacked_model_self_control.predict(X_sc_test)\n",
        "\n",
        "# Calculate the Mean Squared Error (MSE) for each category to evaluate the models' performance\n",
        "mse_well_being_linear = mean_squared_error(Y_wb_test, Y_wb_linear_pred)\n",
        "mse_sociality_linear = mean_squared_error(Y_so_test, Y_so_linear_pred)\n",
        "mse_emotionality_linear = mean_squared_error(Y_em_test, Y_em_linear_pred)\n",
        "mse_self_control_linear = mean_squared_error(Y_sc_test, Y_sc_linear_pred)\n",
        "\n",
        "mse_well_being_ridge = mean_squared_error(Y_wb_test, Y_wb_ridge_pred)\n",
        "mse_sociality_ridge = mean_squared_error(Y_so_test, Y_so_ridge_pred)\n",
        "mse_emotionality_ridge = mean_squared_error(Y_em_test, Y_em_ridge_pred)\n",
        "mse_self_control_ridge = mean_squared_error(Y_sc_test, Y_sc_ridge_pred)\n",
        "\n",
        "mse_well_being_lasso = mean_squared_error(Y_wb_test, Y_wb_lasso_pred)\n",
        "mse_sociality_lasso = mean_squared_error(Y_so_test, Y_so_lasso_pred)\n",
        "mse_emotionality_lasso = mean_squared_error(Y_em_test, Y_em_lasso_pred)\n",
        "mse_self_control_lasso = mean_squared_error(Y_sc_test, Y_sc_lasso_pred)\n",
        "\n",
        "mse_well_being_stacked = mean_squared_error(Y_wb_test, Y_wb_stacked_pred)\n",
        "mse_sociality_stacked = mean_squared_error(Y_so_test, Y_so_stacked_pred)\n",
        "mse_emotionality_stacked = mean_squared_error(Y_em_test, Y_em_stacked_pred)\n",
        "mse_self_control_stacked = mean_squared_error(Y_sc_test, Y_sc_stacked_pred)\n",
        "\n",
        "# Print MSE values for all models\n",
        "print(\"Linear Regression:\")\n",
        "print(f\"Mean Squared Error - Well-Being: {mse_well_being_linear}\")\n",
        "print(f\"Mean Squared Error - Sociality: {mse_sociality_linear}\")\n",
        "print(f\"Mean Squared Error - Emotionality: {mse_emotionality_linear}\")\n",
        "print(f\"Mean Squared Error - Self-Control: {mse_self_control_linear}\")\n",
        "\n",
        "print(\"\\nRidge Regression:\")\n",
        "print(f\"Mean Squared Error - Well-Being: {mse_well_being_ridge}\")\n",
        "print(f\"Mean Squared Error - Sociality: {mse_sociality_ridge}\")\n",
        "print(f\"Mean Squared Error - Emotionality: {mse_emotionality_ridge}\")\n",
        "print(f\"Mean Squared Error - Self-Control: {mse_self_control_ridge}\")\n",
        "\n",
        "print(\"\\nLasso Regression:\")\n",
        "print(f\"Mean Squared Error - Well-Being: {mse_well_being_lasso}\")\n",
        "print(f\"Mean Squared Error - Sociality: {mse_sociality_lasso}\")\n",
        "print(f\"Mean Squared Error - Emotionality: {mse_emotionality_lasso}\")\n",
        "print(f\"Mean Squared Error - Self-Control: {mse_self_control_lasso}\")\n",
        "\n",
        "print(\"\\nStacked Model (Linear, Ridge, Lasso):\")\n",
        "print(f\"Mean Squared Error - Well-Being: {mse_well_being_stacked}\")\n",
        "print(f\"Mean Squared Error - Sociality: {mse_sociality_stacked}\")\n",
        "print(f\"Mean Squared Error - Emotionality: {mse_emotionality_stacked}\")\n",
        "print(f\"Mean Squared Error - Self-Control: {mse_self_control_stacked}\")\n",
        "\n",
        "\n",
        "print(Y_wb_pred)\n",
        "print(Y_so_pred )\n",
        "print(Y_em_pred)\n",
        "print(Y_sc_pred)\n",
        "\n",
        "print(Y_wb_linear_pred)\n",
        "print(Y_so_linear_pred)\n",
        "print(Y_em_linear_pred)\n",
        "print(Y_sc_linear_pred)\n",
        "\n",
        "print()\n",
        "print()\n",
        "print()\n",
        "print()\n",
        "\n",
        "print()\n",
        "print()\n",
        "print()\n",
        "print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAK9prSWyMwv",
        "outputId": "bbb8ba4d-10c2-4acf-897e-57e3f0fe3f8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression:\n",
            "Mean Squared Error - Well-Being: 0.3515719035459583\n",
            "Mean Squared Error - Sociality: 2.6119978129719796\n",
            "Mean Squared Error - Emotionality: 3.6743586414789036\n",
            "Mean Squared Error - Self-Control: 3.9020112000404503\n",
            "\n",
            "Ridge Regression:\n",
            "Mean Squared Error - Well-Being: 0.3595036297303225\n",
            "Mean Squared Error - Sociality: 2.6344123902027006\n",
            "Mean Squared Error - Emotionality: 3.6838819599004546\n",
            "Mean Squared Error - Self-Control: 3.9053607076760795\n",
            "\n",
            "Lasso Regression:\n",
            "Mean Squared Error - Well-Being: 3.716824777853955\n",
            "Mean Squared Error - Sociality: 5.717790321423256\n",
            "Mean Squared Error - Emotionality: 5.873177245943306\n",
            "Mean Squared Error - Self-Control: 5.833676440522524\n",
            "\n",
            "Stacked Model (Linear, Ridge, Lasso):\n",
            "Mean Squared Error - Well-Being: 0.3450574651589742\n",
            "Mean Squared Error - Sociality: 2.911768595065594\n",
            "Mean Squared Error - Emotionality: 3.753948285360361\n",
            "Mean Squared Error - Self-Control: 4.336941536448465\n",
            "[23.96257624 26.55563965 17.28279481 25.85233017 40.24788732 35.05464754\n",
            " 29.09718028 19.87678316 29.79913362 28.54484893 33.74759988 25.26474567\n",
            " 36.6126895  40.24788732 29.82341779 24.85356397 28.72243708 31.64362827\n",
            " 27.6313918  33.27349977 29.82341779 36.00121309 36.95472099 37.01759256\n",
            " 29.09718028 25.85233017 37.20890848 40.24788732 29.48497373 27.84537683]\n",
            "[20.1352313  25.66578955 18.67254586 35.52305012 41.3684605  38.98085611\n",
            " 30.8943253  29.12377836 36.2244962  30.41783115 36.12777953 29.22630491\n",
            " 27.09214891 41.3684605  29.69468478 20.08110359 28.17530931 35.51892304\n",
            " 29.62395841 35.99599932 29.69468478 35.57086361 41.16806491 34.50045282\n",
            " 30.8943253  35.52305012 39.74508914 41.3684605  37.11984836 30.26188333]\n",
            "[20.49452037 17.25249199 28.65102102 27.4013589  32.95579916 42.49832405\n",
            " 28.3986998  27.56672614 32.96904384 27.50549196 32.51682366 25.08573502\n",
            " 32.89560994 32.95579916 29.81198898 21.11654812 30.17815573 33.49247002\n",
            " 25.39994733 36.25101376 29.81198898 28.6156767  36.79289718 35.37732088\n",
            " 28.3986998  27.4013589  38.85020829 32.95579916 27.6550689  26.8511651 ]\n",
            "[21.62703065 19.81303607 23.77343174 22.06734892 42.0162592  40.01994686\n",
            " 37.39300312 30.02630839 30.80925258 29.3549841  36.14752475 31.58346806\n",
            " 28.90126388 42.0162592  29.79248785 21.25786205 33.29829662 32.98181735\n",
            " 29.12951016 30.65762862 29.79248785 32.35248531 41.46322989 35.85804643\n",
            " 37.39300312 22.06734892 37.93646565 42.0162592  39.31739334 36.32992269]\n",
            "[23.96257624 26.55563965 17.28279481 25.85233017 40.24788732 35.05464754\n",
            " 29.09718028 19.87678316 29.79913362 28.54484893 33.74759988 25.26474567\n",
            " 36.6126895  40.24788732 29.82341779 24.85356397 28.72243708 31.64362827\n",
            " 27.6313918  33.27349977 29.82341779 36.00121309 36.95472099 37.01759256\n",
            " 29.09718028 25.85233017 37.20890848 40.24788732 29.48497373 27.84537683]\n",
            "[20.1352313  25.66578955 18.67254586 35.52305012 41.3684605  38.98085611\n",
            " 30.8943253  29.12377836 36.2244962  30.41783115 36.12777953 29.22630491\n",
            " 27.09214891 41.3684605  29.69468478 20.08110359 28.17530931 35.51892304\n",
            " 29.62395841 35.99599932 29.69468478 35.57086361 41.16806491 34.50045282\n",
            " 30.8943253  35.52305012 39.74508914 41.3684605  37.11984836 30.26188333]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest Regression"
      ],
      "metadata": {
        "id": "G4F8K-INxd3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Load your dataset (replace 'your_dataset.csv' with the actual file path)\n",
        "data = pd.read_csv('duplicate1.csv')\n",
        "\n",
        "# Define the features (questionnaire responses) and target variables\n",
        "# For each category, X represents the features (questionnaire responses)\n",
        "X_well_being = data[['wb_q1', 'wb_q2', 'wb_q3', 'wb_q4', 'wb_q5', 'wb_q6', 'wb_q7', 'wb_q8', 'wb_q9', 'wb_10']]\n",
        "X_sociality = data[['soc_q1', 'soc_q2', 'soc_q3', 'soc_q4', 'soc_q5', 'soc_q6', 'soc_q7', 'soc_q8', 'soc_q9', 'soc_q10']]\n",
        "X_emotionality = data[['emo_q1', 'emo_q2', 'emo_q3', 'emo_q4', 'emo_q5', 'emo_q6', 'emo_q7', 'emo_q8', 'emo_q9', 'emo_q10']]\n",
        "X_self_control = data[['sc_q1', 'sc_q2', 'sc_q3', 'sc_q4', 'sc_q5', 'sc_q6', 'sc_q7', 'sc_q8', 'sc_q9', 'sc_q10']]\n",
        "\n",
        "# Y represents the target variables for each category (the final numerical values)\n",
        "Y_well_being = data['Final Well-Being Value']\n",
        "Y_sociality = data['Final Sociality Value']\n",
        "Y_emotionality = data['Final Emotionality Value']\n",
        "Y_self_control = data['Final Self-Control Value']\n",
        "\n",
        "# Impute missing values using SimpleImputer with 'mean' strategy\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_well_being = imputer.fit_transform(X_well_being)\n",
        "X_sociality = imputer.fit_transform(X_sociality)\n",
        "X_emotionality = imputer.fit_transform(X_emotionality)\n",
        "X_self_control = imputer.fit_transform(X_self_control)\n",
        "\n",
        "# Split each category's data into training and testing sets\n",
        "X_wb_train, X_wb_test, Y_wb_train, Y_wb_test = train_test_split(X_well_being, Y_well_being, test_size=0.2, random_state=42)\n",
        "X_so_train, X_so_test, Y_so_train, Y_so_test = train_test_split(X_sociality, Y_sociality, test_size=0.2, random_state=42)\n",
        "X_em_train, X_em_test, Y_em_train, Y_em_test = train_test_split(X_emotionality, Y_emotionality, test_size=0.2, random_state=42)\n",
        "X_sc_train, X_sc_test, Y_sc_train, Y_sc_test = train_test_split(X_self_control, Y_self_control, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create Random Forest Regression models for each category\n",
        "model_well_being = RandomForestRegressor(n_estimators=40, random_state=42)\n",
        "model_sociality = RandomForestRegressor(n_estimators=40, random_state=42)\n",
        "model_emotionality = RandomForestRegressor(n_estimators=40, random_state=42)\n",
        "model_self_control = RandomForestRegressor(n_estimators=40, random_state=42)\n",
        "\n",
        "# Fit each model to its respective training data\n",
        "model_well_being.fit(X_wb_train, Y_wb_train)\n",
        "model_sociality.fit(X_so_train, Y_so_train)\n",
        "model_emotionality.fit(X_em_train, Y_em_train)\n",
        "model_self_control.fit(X_sc_train, Y_sc_train)\n",
        "\n",
        "# Predict the final numerical values for each category using the respective models\n",
        "Y_wb_pred = model_well_being.predict(X_wb_test)\n",
        "Y_so_pred = model_sociality.predict(X_so_test)\n",
        "Y_em_pred = model_emotionality.predict(X_em_test)\n",
        "Y_sc_pred = model_self_control.predict(X_sc_test)\n",
        "\n",
        "# Calculate the Mean Squared Error (MSE) for each category to evaluate the models' performance\n",
        "mse_well_being = mean_squared_error(Y_wb_test, Y_wb_pred)\n",
        "mse_sociality = mean_squared_error(Y_so_test, Y_so_pred)\n",
        "mse_emotionality = mean_squared_error(Y_em_test, Y_em_pred)\n",
        "mse_self_control = mean_squared_error(Y_sc_test, Y_sc_pred)\n",
        "\n",
        "print(f\"Mean Squared Error - Well-Being: {mse_well_being}\")\n",
        "print(f\"Mean Squared Error - Sociality: {mse_sociality}\")\n",
        "print(f\"Mean Squared Error - Emotionality: {mse_emotionality}\")\n",
        "print(f\"Mean Squared Error - Self-Control: {mse_self_control}\")\n",
        "\n",
        "print(Y_wb_pred)\n",
        "print(Y_so_pred )\n",
        "print(Y_em_pred)\n",
        "print(Y_sc_pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAGbwU-bxegQ",
        "outputId": "69d36521-3400-4162-9bf4-e6cbf13e4c90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error - Well-Being: 1.4679166666666668\n",
            "Mean Squared Error - Sociality: 2.4215625000000003\n",
            "Mean Squared Error - Emotionality: 7.019958333333336\n",
            "Mean Squared Error - Self-Control: 2.6114791666666677\n",
            "[24.6   29.175 18.875 26.325 39.875 34.675 27.85  18.975 30.125 28.8\n",
            " 34.375 25.3   34.95  39.875 30.    26.05  30.475 31.6   28.725 32.9\n",
            " 30.    35.05  38.625 37.75  27.85  26.325 36.075 39.875 30.65  30.475]\n",
            "[20.95  26.4   16.85  35.2   41.075 38.7   35.25  25.675 36.1   31.2\n",
            " 37.325 30.825 27.1   41.075 30.    24.2   28.325 35.025 29.75  37.7\n",
            " 30.    36.075 40.475 34.6   35.25  35.2   37.8   41.075 36.675 30.25 ]\n",
            "[21.375 18.325 24.95  26.2   28.4   42.2   36.125 22.6   32.675 27.925\n",
            " 33.35  24.95  33.875 28.4   30.    22.05  29.35  34.55  26.225 36.6\n",
            " 30.    26.925 36.625 31.7   36.125 26.2   38.4   28.4   28.    26.35 ]\n",
            "[22.025 23.575 19.65  23.775 38.8   39.875 35.4   26.25  30.625 30.1\n",
            " 36.675 32.225 28.65  38.8   30.    23.625 33.65  34.    29.3   30.95\n",
            " 30.    33.125 38.6   35.6   35.4   23.775 36.95  38.8   40.15  36.475]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e31DpOHNoqPQ"
      },
      "source": [
        "Gradient Boosting Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rA_2Jds02_8Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc2c8d55-b851-4076-b3c3-7813956466dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error - Well-Being: 0.8341194844428715\n",
            "Mean Squared Error - Sociality: 1.325985379761509\n",
            "Mean Squared Error - Emotionality: 3.331231185564374\n",
            "Mean Squared Error - Self-Control: 0.1882469774562512\n",
            "[24.11558715 26.88931512 15.12302194 25.83846484 40.43550885 34.77188535\n",
            " 25.64222028 18.07725505 30.00188475 28.91537417 33.83384523 25.0816255\n",
            " 36.71969171 40.43550885 30.29388053 25.35505989 29.34609701 31.3308733\n",
            " 28.29632593 32.78621466 30.29388053 35.80524469 37.15630135 36.39287859\n",
            " 25.64222028 25.83846484 36.95126453 40.43550885 29.75556657 28.37597953]\n",
            "[20.10009774 25.13624355 12.1289673  35.25420443 40.87939813 39.01640473\n",
            " 35.27032206 25.10061652 36.4518232  31.02036181 37.98382644 30.05679152\n",
            " 28.02825306 40.87939813 29.66046344 22.21786981 29.16822128 35.29535757\n",
            " 30.07165101 37.5195982  29.66046344 35.87786699 39.61171237 35.0901784\n",
            " 35.27032206 35.25420443 38.69042199 40.87939813 37.11653393 29.57381519]\n",
            "[21.25997579 18.07611666 20.0081785  26.70306737 27.63624394 41.6523243\n",
            " 31.45485593 22.26218849 32.52392097 27.91758691 32.9935185  24.96787119\n",
            " 32.99828671 27.63624394 30.05252504 21.25683424 29.53428258 34.25816187\n",
            " 26.01545202 36.64335893 30.05252504 28.75190573 36.84063415 35.20009035\n",
            " 31.45485593 26.70306737 38.58134546 27.63624394 27.80515548 27.27939525]\n",
            "[21.91994189 21.0897228  15.03634586 22.19294055 42.31793861 39.36597051\n",
            " 37.9104227  24.99728332 31.10498982 30.44890508 36.69759024 32.12707889\n",
            " 28.9655249  42.31793861 30.03209368 22.80503984 33.61705125 34.62892485\n",
            " 29.24922678 30.74953739 30.03209368 33.36202795 39.1097101  35.72475495\n",
            " 37.9104227  22.19294055 37.53140761 42.31793861 39.09232231 35.856657  ]\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Load your dataset (replace 'your_dataset.csv' with the actual file path)\n",
        "data = pd.read_csv('duplicate1.csv')\n",
        "\n",
        "# Assuming your dataset has columns 'Q1' to 'Q40' for the 40 questionnaire responses\n",
        "# For each category, X represents the features (questionnaire responses)\n",
        "X_well_being = data[['wb_q1','wb_q2','wb_q3','wb_q4','wb_q5','wb_q6','wb_q7','wb_q8','wb_q9','wb_10']]  # Replace ... with the actual column names\n",
        "X_sociality = data[['soc_q1','soc_q2','soc_q3','soc_q4','soc_q5','soc_q6','soc_q7','soc_q8','soc_q9','soc_q10']]  # Replace ... with the actual column names\n",
        "X_emotionality = data[['emo_q1','emo_q2','emo_q3','emo_q4','emo_q5','emo_q6','emo_q7','emo_q8','emo_q9','emo_q10']]  # Replace ... with the actual column names\n",
        "X_self_control = data[['sc_q1','sc_q2','sc_q3','sc_q4','sc_q5','sc_q6','sc_q7','sc_q8','sc_q9','sc_q10']]  # Replace ... with the actual column names\n",
        "\n",
        "# Y represents the target variables for each category (the final numerical values)\n",
        "Y_well_being = data['Final Well-Being Value']\n",
        "Y_sociality = data['Final Sociality Value']\n",
        "Y_emotionality = data['Final Emotionality Value']\n",
        "Y_self_control = data['Final Self-Control Value']\n",
        "\n",
        "# Use SimpleImputer to handle missing values\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_well_being = imputer.fit_transform(X_well_being)\n",
        "X_sociality = imputer.fit_transform(X_sociality)\n",
        "X_emotionality = imputer.fit_transform(X_emotionality)\n",
        "X_self_control = imputer.fit_transform(X_self_control)\n",
        "\n",
        "# Split each category's data into training and testing sets\n",
        "X_wb_train, X_wb_test, Y_wb_train, Y_wb_test = train_test_split(X_well_being, Y_well_being, test_size=0.2, random_state=42)\n",
        "X_so_train, X_so_test, Y_so_train, Y_so_test = train_test_split(X_sociality, Y_sociality, test_size=0.2, random_state=42)\n",
        "X_em_train, X_em_test, Y_em_train, Y_em_test = train_test_split(X_emotionality, Y_emotionality, test_size=0.2, random_state=42)\n",
        "X_sc_train, X_sc_test, Y_sc_train, Y_sc_test = train_test_split(X_self_control, Y_self_control, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create Gradient Boosting Regression models for each category\n",
        "model_well_being = GradientBoostingRegressor()\n",
        "model_sociality = GradientBoostingRegressor()\n",
        "model_emotionality = GradientBoostingRegressor()\n",
        "model_self_control = GradientBoostingRegressor()\n",
        "\n",
        "# Fit each model to its respective training data\n",
        "model_well_being.fit(X_wb_train, Y_wb_train)\n",
        "model_sociality.fit(X_so_train, Y_so_train)\n",
        "model_emotionality.fit(X_em_train, Y_em_train)\n",
        "model_self_control.fit(X_sc_train, Y_sc_train)\n",
        "\n",
        "# Predict the final numerical values for each category using the respective models\n",
        "Y_wb_pred = model_well_being.predict(X_wb_test)\n",
        "Y_so_pred = model_sociality.predict(X_so_test)\n",
        "Y_em_pred = model_emotionality.predict(X_em_test)\n",
        "Y_sc_pred = model_self_control.predict(X_sc_test)\n",
        "\n",
        "# Calculate the Mean Squared Error (MSE) for each category to evaluate the models' performance\n",
        "mse_well_being = mean_squared_error(Y_wb_test, Y_wb_pred)\n",
        "mse_sociality = mean_squared_error(Y_so_test, Y_so_pred)\n",
        "mse_emotionality = mean_squared_error(Y_em_test, Y_em_pred)\n",
        "mse_self_control = mean_squared_error(Y_sc_test, Y_sc_pred)\n",
        "\n",
        "print(f\"Mean Squared Error - Well-Being: {mse_well_being}\")\n",
        "print(f\"Mean Squared Error - Sociality: {mse_sociality}\")\n",
        "print(f\"Mean Squared Error - Emotionality: {mse_emotionality}\")\n",
        "print(f\"Mean Squared Error - Self-Control: {mse_self_control}\")\n",
        "\n",
        "print(Y_wb_pred)\n",
        "print(Y_so_pred)\n",
        "print(Y_em_pred)\n",
        "print(Y_sc_pred)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDCEvptMOdTg"
      },
      "source": [
        "Gradient Boosting Regression.GRID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xALvJOuP0Jl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "348e987c-cf6d-404e-fe92-fc06b6501f63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Well-Being category...\n",
            "Best Hyperparameters for Well-Being: {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 100}\n",
            "[24.04414281 26.99420766 15.01811329 25.92541243 42.76599627 35.05191055\n",
            " 26.61089653 18.0248427  29.96832475 29.04285609 34.06924588 25.02550787\n",
            " 37.04897113 42.76599627 30.15377894 25.01639414 29.06642056 31.80725129\n",
            " 28.00565277 32.93330331 30.15377894 35.96216763 36.99398597 36.70428997\n",
            " 26.61089653 25.92541243 37.02308149 42.76599627 29.98513497 28.03311864]\n",
            "Mean Squared Error - Well-Being: 1.1526546872021737\n",
            "Processing Sociality category...\n",
            "Best Hyperparameters for Sociality: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300}\n",
            "[19.99115467 24.99341092 12.01484538 34.99039133 41.57154585 38.89464674\n",
            " 35.02383248 25.00573073 36.12170231 30.98032851 38.09873842 29.99127663\n",
            " 28.03983148 41.57154585 29.94089878 22.00504807 29.00711266 35.14422769\n",
            " 30.02448489 37.96603731 29.94089878 35.97062714 40.68093038 35.07780062\n",
            " 35.02383248 34.99039133 38.91070125 41.57154585 37.00804586 29.84269972]\n",
            "Mean Squared Error - Sociality: 1.1190612969226066\n",
            "Processing Emotionality category...\n",
            "Best Hyperparameters for Emotionality: {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 300}\n",
            "[21.00125394 18.00034993 19.99937114 26.99871835 28.74424254 41.9999524\n",
            " 33.2398946  22.00024763 32.99690706 28.00158551 32.99759606 25.00006041\n",
            " 32.99905269 28.74424254 30.00014596 21.00130853 30.00162887 34.00156589\n",
            " 25.99950757 36.99790293 30.00014596 29.00025694 37.00425655 35.00121284\n",
            " 33.2398946  26.99871835 38.99728284 28.74424254 27.99628904 27.00306214]\n",
            "Mean Squared Error - Emotionality: 3.0095970957502427\n",
            "Processing Self-Control category...\n",
            "Best Hyperparameters for Self-Control: {'learning_rate': 0.2, 'max_depth': 4, 'n_estimators': 200}\n",
            "[21.99905117 21.000368   14.99977928 21.99894314 39.81090959 39.99641154\n",
            " 37.16629607 25.00000356 30.99651605 29.99933937 36.00067541 32.00185027\n",
            " 29.99783464 39.81090959 30.01521902 23.00014061 33.01418491 34.00209382\n",
            " 28.99996347 31.00080651 30.01521902 33.00069764 38.99989769 35.99712078\n",
            " 37.16629607 21.99894314 37.99877115 39.81090959 39.00016803 36.00201176]\n",
            "Mean Squared Error - Self-Control: 0.481079349940786\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import mean_squared_error\n",
        "# Load your dataset (replace 'your_dataset.csv' with the actual file path)\n",
        "data = pd.read_csv('duplicate1.csv')\n",
        "# Define the columns for each category\n",
        "categories = [\"Well-Being\", \"Sociality\", \"Emotionality\", \"Self-Control\"]\n",
        "category_columns = {\n",
        "    \"Well-Being\": ['wb_q1', 'wb_q2', 'wb_q3', 'wb_q4', 'wb_q5', 'wb_q6', 'wb_q7', 'wb_q8', 'wb_q9', 'wb_10'],\n",
        "    \"Sociality\": ['soc_q1', 'soc_q2', 'soc_q3', 'soc_q4', 'soc_q5', 'soc_q6', 'soc_q7', 'soc_q8', 'soc_q9', 'soc_q10'],\n",
        "    \"Emotionality\": ['emo_q1', 'emo_q2', 'emo_q3', 'emo_q4', 'emo_q5', 'emo_q6', 'emo_q7', 'emo_q8', 'emo_q9', 'emo_q10'],\n",
        "    \"Self-Control\": ['sc_q1', 'sc_q2', 'sc_q3', 'sc_q4', 'sc_q5', 'sc_q6', 'sc_q7', 'sc_q8', 'sc_q9', 'sc_q10']\n",
        "}\n",
        "\n",
        "# Dictionary to store best hyperparameters for each category\n",
        "best_hyperparameters = {}\n",
        "# Loop through each category\n",
        "for category in categories:\n",
        "    print(f\"Processing {category} category...\")\n",
        "\n",
        "    # Extract features and labels for the current category\n",
        "    X = data[category_columns[category]]\n",
        "    Y = data[f\"Final {category} Value\"]\n",
        "\n",
        "    # Split data into training and testing sets\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Impute missing values in both training and testing sets\n",
        "    imputer = SimpleImputer(strategy='mean')\n",
        "    X_train = imputer.fit_transform(X_train)\n",
        "    X_test = imputer.transform(X_test)\n",
        "\n",
        "    # Define the hyperparameters and their possible values\n",
        "    param_grid = {\n",
        "        'n_estimators': [100, 200, 300],\n",
        "        'learning_rate': [0.01, 0.1, 0.2],\n",
        "        'max_depth': [3, 4, 5],\n",
        "    }\n",
        "    # Create a GradientBoostingRegressor model\n",
        "    model = GradientBoostingRegressor()\n",
        "\n",
        "    # Perform hyperparameter tuning using GridSearchCV\n",
        "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring='neg_mean_squared_error', cv=5)\n",
        "    grid_search.fit(X_train, Y_train)\n",
        "\n",
        "    # Get the best hyperparameters for the current category\n",
        "    best_params = grid_search.best_params_\n",
        "    print(f\"Best Hyperparameters for {category}:\", best_params)\n",
        "\n",
        "    # Get the best model with the tuned hyperparameters\n",
        "    best_gb_model = grid_search.best_estimator_\n",
        "\n",
        "    # Store the best hyperparameters in the dictionary\n",
        "    best_hyperparameters[category] = best_params\n",
        "    # Now, you can use the best_gb_model for predictions\n",
        "    Y_pred = best_gb_model.predict(X_test)\n",
        "    print(Y_pred)\n",
        "\n",
        "    # Evaluate the model's performance using MSE (Mean Squared Error) for the current category\n",
        "    mse = mean_squared_error(Y_test, Y_pred)\n",
        "    print(f\"Mean Squared Error - {category}: {mse}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient Boosting Regression.GridSearchCV(ridge,lasso)"
      ],
      "metadata": {
        "id": "S0f9wy_B4UYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.linear_model import Ridge, Lasso, LinearRegression\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load your dataset (replace 'your_dataset.csv' with the actual file path)\n",
        "data = pd.read_csv('duplicate1.csv')\n",
        "\n",
        "# Define the columns for each category\n",
        "categories = [\"Well-Being\", \"Sociality\", \"Emotionality\", \"Self-Control\"]\n",
        "category_columns = {\n",
        "    \"Well-Being\": ['wb_q1', 'wb_q2', 'wb_q3', 'wb_q4', 'wb_q5', 'wb_q6', 'wb_q7', 'wb_q8', 'wb_q9', 'wb_10'],\n",
        "    \"Sociality\": ['soc_q1', 'soc_q2', 'soc_q3', 'soc_q4', 'soc_q5', 'soc_q6', 'soc_q7', 'soc_q8', 'soc_q9', 'soc_q10'],\n",
        "    \"Emotionality\": ['emo_q1', 'emo_q2', 'emo_q3', 'emo_q4', 'emo_q5', 'emo_q6', 'emo_q7', 'emo_q8', 'emo_q9', 'emo_q10'],\n",
        "    \"Self-Control\": ['sc_q1', 'sc_q2', 'sc_q3', 'sc_q4', 'sc_q5', 'sc_q6', 'sc_q7', 'sc_q8', 'sc_q9', 'sc_q10']\n",
        "}\n",
        "\n",
        "# Dictionary to store best hyperparameters for each category\n",
        "best_hyperparameters = {}\n",
        "\n",
        "# Loop through each category\n",
        "for category in categories:\n",
        "    print(f\"Processing {category} category...\")\n",
        "\n",
        "    # Extract features and labels for the current category\n",
        "    X = data[category_columns[category]]\n",
        "    Y = data[f\"Final {category} Value\"]\n",
        "\n",
        "    # Split data into training and testing sets\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Impute missing values in both training and testing sets\n",
        "    imputer = SimpleImputer(strategy='mean')\n",
        "    X_train = imputer.fit_transform(X_train)\n",
        "    X_test = imputer.transform(X_test)\n",
        "\n",
        "    # Define the hyperparameters and their possible values for Gradient Boosting\n",
        "    gb_param_grid = {\n",
        "        'n_estimators': [100, 200, 300],\n",
        "        'learning_rate': [0.01, 0.1, 0.2],\n",
        "        'max_depth': [3, 4, 5],\n",
        "    }\n",
        "\n",
        "    # Create a GradientBoostingRegressor model\n",
        "    gb_model = GradientBoostingRegressor()\n",
        "\n",
        "    # Perform hyperparameter tuning using GridSearchCV for Gradient Boosting\n",
        "    gb_grid_search = GridSearchCV(estimator=gb_model, param_grid=gb_param_grid, scoring='neg_mean_squared_error', cv=5)\n",
        "    gb_grid_search.fit(X_train, Y_train)\n",
        "\n",
        "    # Get the best hyperparameters for the current category for Gradient Boosting\n",
        "    best_gb_params = gb_grid_search.best_params_\n",
        "    print(f\"Best Hyperparameters for {category} (Gradient Boosting):\", best_gb_params)\n",
        "\n",
        "    # Get the best model with the tuned hyperparameters for Gradient Boosting\n",
        "    best_gb_model = gb_grid_search.best_estimator_\n",
        "\n",
        "    # Store the best hyperparameters in the dictionary\n",
        "    best_hyperparameters[category] = best_gb_params\n",
        "\n",
        "    # Use the best_gb_model for predictions\n",
        "    Y_gb_pred = best_gb_model.predict(X_test)\n",
        "    print(Y_gb_pred)\n",
        "\n",
        "    # Evaluate the Gradient Boosting model's performance using MSE (Mean Squared Error) for the current category\n",
        "    mse_gb = mean_squared_error(Y_test, Y_gb_pred)\n",
        "    print(f\"Mean Squared Error - {category} (Gradient Boosting): {mse_gb}\")\n",
        "\n",
        "    # Apply Ridge Regression\n",
        "    ridge_model = Ridge(alpha=1.0)\n",
        "    ridge_model.fit(X_train, Y_train)\n",
        "    Y_ridge_pred = ridge_model.predict(X_test)\n",
        "    print(Y_ridge_pred)\n",
        "\n",
        "    # Evaluate Ridge Regression's performance using MSE\n",
        "    mse_ridge = mean_squared_error(Y_test, Y_ridge_pred)\n",
        "    print(f\"Mean Squared Error - {category} (Ridge Regression): {mse_ridge}\")\n",
        "\n",
        "    # Apply Lasso Regression\n",
        "    lasso_model = Lasso(alpha=1.0)\n",
        "    lasso_model.fit(X_train, Y_train)\n",
        "    Y_lasso_pred = lasso_model.predict(X_test)\n",
        "    print(Y_lasso_pred)\n",
        "\n",
        "    # Evaluate Lasso Regression's performance using MSE\n",
        "    mse_lasso = mean_squared_error(Y_test, Y_lasso_pred)\n",
        "    print(f\"Mean Squared Error - {category} (Lasso Regression): {mse_lasso}\")\n",
        "\n",
        "    # Create a stacked model using Gradient Boosting, Ridge, and Lasso models\n",
        "    estimators = [\n",
        "        ('gb', best_gb_model),\n",
        "        ('ridge', ridge_model),\n",
        "        ('lasso', lasso_model)\n",
        "    ]\n",
        "\n",
        "    stacked_model = StackingRegressor(estimators=estimators, final_estimator=LinearRegression())\n",
        "\n",
        "    # Fit the stacked model\n",
        "    stacked_model.fit(X_train, Y_train)\n",
        "\n",
        "    # Predict the final numerical values using the stacked model\n",
        "    Y_stacked_pred = stacked_model.predict(X_test)\n",
        "    print(Y_stacked_pred)\n",
        "\n",
        "    # Calculate the Mean Squared Error (MSE) for the stacked model\n",
        "    mse_stacked = mean_squared_error(Y_test, Y_stacked_pred)\n",
        "\n",
        "    # Print MSE value for the stacked model\n",
        "    print(f\"Mean Squared Error - {category} (Stacked Model): {mse_stacked}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDfDv6S84e8r",
        "outputId": "fcce49f2-3e4c-415e-c468-e5719f4d38f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Well-Being category...\n",
            "Best Hyperparameters for Well-Being (Gradient Boosting): {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 100}\n",
            "[24.04414281 26.99420766 15.01811329 25.92541243 42.76599627 35.05191055\n",
            " 26.61089653 18.0248427  29.96832475 29.04285609 34.06924588 25.02550787\n",
            " 37.04897113 42.76599627 30.15377894 25.01639414 29.06642056 31.80725129\n",
            " 28.00565277 32.93330331 30.15377894 35.96216763 36.99398597 36.70428997\n",
            " 26.61089653 25.92541243 37.02308149 42.76599627 29.98513497 28.03311864]\n",
            "Mean Squared Error - Well-Being (Gradient Boosting): 1.1526546872021737\n",
            "[23.97550833 26.57384873 17.31318364 25.85666195 40.23011852 35.04779791\n",
            " 29.10016669 19.90585491 29.80519087 28.55570799 33.74884975 25.27173418\n",
            " 36.60757964 40.23011852 29.82990682 24.8695446  28.73416417 31.65050355\n",
            " 27.64597416 33.26226946 29.82990682 35.99592242 36.94041972 37.0090076\n",
            " 29.10016669 25.85666195 37.19231013 40.23011852 29.5016153  27.85916477]\n",
            "Mean Squared Error - Well-Being (Ridge Regression): 0.3561513032605531\n",
            "[25.41905585 27.35945394 21.47516313 26.30363742 38.06666638 34.2254869\n",
            " 30.08976744 23.31995703 29.91421055 29.21572111 33.46481619 26.73050823\n",
            " 34.82428607 38.06666638 30.43057529 26.70058666 30.21472337 32.14141154\n",
            " 29.40867794 32.78843104 30.43057529 35.23920624 35.41259759 35.84194221\n",
            " 30.08976744 26.30363742 35.58738864 38.06666638 31.07308213 29.44413541]\n",
            "Mean Squared Error - Well-Being (Lasso Regression): 3.709127446162583\n",
            "[24.02984954 26.66216351 17.01374761 26.0189419  40.37608739 35.06654156\n",
            " 28.89586787 19.6605166  29.87366074 28.58977285 33.73716895 25.25404397\n",
            " 36.76334324 40.37608739 29.81448733 24.81953118 28.60078737 31.57242283\n",
            " 27.50615808 33.27217484 29.81448733 35.96180608 37.01520463 36.99561177\n",
            " 28.89586787 26.0189419  37.25960754 40.37608739 29.32782269 27.73401594]\n",
            "Mean Squared Error - Well-Being (Stacked Model): 0.303525856721285\n",
            "Processing Sociality category...\n",
            "Best Hyperparameters for Sociality (Gradient Boosting): {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200}\n",
            "[20.00563886 25.01101721 12.01515454 34.98667263 41.28142233 38.91236015\n",
            " 35.07788874 25.02471654 36.20799393 30.95446606 38.0803853  29.98448075\n",
            " 28.06309338 41.28142233 29.83439372 22.01242302 29.02659755 35.15217155\n",
            " 30.05002741 37.86958229 29.83439372 35.97258781 40.22641999 35.08166895\n",
            " 35.07788874 34.98667263 38.80359979 41.28142233 36.99472038 29.74865457]\n",
            "Mean Squared Error - Sociality (Gradient Boosting): 1.1455666577126684\n",
            "[20.14415001 25.66032719 18.72469349 35.52278149 41.34613315 38.95041085\n",
            " 30.89856917 29.18482135 36.19814617 30.43844258 36.15585836 29.23141202\n",
            " 27.10164371 41.34613315 29.69792682 20.13856742 28.20023416 35.50453124\n",
            " 29.62286096 36.04219242 29.69792682 35.57746981 41.14590988 34.50343334\n",
            " 30.89856917 35.52278149 39.70238303 41.34613315 37.11583707 30.24699819]\n",
            "Mean Squared Error - Sociality (Ridge Regression): 2.626812013449629\n",
            "[22.31183793 28.42242472 19.52163276 34.03298081 39.33784735 36.18269336\n",
            " 30.88555244 31.5888107  33.93511339 29.89130513 34.69231166 30.72513983\n",
            " 27.12528545 39.33784735 30.69348472 22.39298035 29.32940955 34.57172922\n",
            " 30.6907659  35.39535219 30.69348472 35.32464796 38.54544138 34.08491033\n",
            " 30.88555244 34.03298081 38.50019577 39.33784735 35.93295667 30.97466013]\n",
            "Mean Squared Error - Sociality (Lasso Regression): 5.707261772088556\n",
            "[19.78584695 25.20064131 14.77523206 35.25668561 41.47514784 39.00295144\n",
            " 33.07017533 26.93657231 36.21688982 30.62461851 37.22147227 29.57732582\n",
            " 27.45226632 41.47514784 29.71134257 20.85708085 28.54500249 35.35414898\n",
            " 29.79173254 37.07941894 29.71134257 35.85021967 40.79387122 34.83895254\n",
            " 33.07017533 35.25668561 39.36717097 41.47514784 37.12511824 29.92796793]\n",
            "Mean Squared Error - Sociality (Stacked Model): 0.8378038624828393\n",
            "Processing Emotionality category...\n",
            "Best Hyperparameters for Emotionality (Gradient Boosting): {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 300}\n",
            "[21.00125394 18.00034993 19.99937114 26.99871835 28.74248503 41.9999524\n",
            " 33.44734762 22.00024763 32.99690706 28.00158551 32.99759606 25.00006041\n",
            " 32.99905269 28.74248503 30.00014596 21.00130853 30.00162887 34.00156589\n",
            " 25.99950757 36.99790293 30.00014596 29.00025694 37.00425655 35.00121284\n",
            " 33.44734762 26.99871835 38.99728284 28.74248503 27.99628904 27.00306214]\n",
            "Mean Squared Error - Emotionality (Gradient Boosting): 3.131239626798217\n",
            "[20.5099167  17.28447846 28.70447763 27.4254332  32.94175204 42.46811697\n",
            " 28.41717124 27.60499704 32.95905541 27.52616963 32.52284912 25.05271364\n",
            " 32.92632952 32.94175204 29.81290042 21.12676036 30.16769842 33.51903376\n",
            " 25.41901898 36.23382505 29.81290042 28.61663377 36.77515888 35.33773184\n",
            " 28.41717124 27.4254332  38.85536022 32.94175204 27.63438848 26.85257233]\n",
            "Mean Squared Error - Emotionality (Ridge Regression): 3.7142277286002208\n",
            "[22.89816339 19.04517984 29.80147682 26.05300167 31.85049999 39.15094835\n",
            " 28.47625949 28.73783202 31.98405221 27.45618385 32.59898843 25.41792478\n",
            " 31.27616942 31.85049999 30.24313608 23.3484246  29.53923551 33.26807915\n",
            " 25.98013136 37.16650318 30.24313608 29.3544566  35.93121985 34.25250714\n",
            " 28.47625949 26.05300167 37.47513589 31.85049999 28.87700316 27.70754798]\n",
            "Mean Squared Error - Emotionality (Lasso Regression): 5.901739079312534\n",
            "[20.43325072 17.47738322 25.17063377 27.5504618  31.45195691 42.62512193\n",
            " 30.26563086 25.27616395 33.07341923 27.75343597 32.61884059 25.04821841\n",
            " 33.17997308 31.45195691 29.78933374 20.83166389 30.19764637 33.65796226\n",
            " 25.61334005 36.20470938 29.78933374 28.63619284 36.85918089 35.27952303\n",
            " 30.26563086 27.5504618  38.96216469 31.45195691 27.57241708 26.7976968 ]\n",
            "Mean Squared Error - Emotionality (Stacked Model): 1.7069872147758127\n",
            "Processing Self-Control category...\n",
            "Best Hyperparameters for Self-Control (Gradient Boosting): {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300}\n",
            "[22.02140782 20.97788383 15.00182002 21.99021941 41.93522075 39.87278552\n",
            " 37.80703642 24.96984334 31.05590772 30.15183836 36.10143604 32.00750541\n",
            " 29.7885763  41.93522075 30.06645196 23.01578973 33.15743078 34.13636009\n",
            " 29.02853007 30.99688753 30.06645196 33.0381747  38.98058368 35.87391416\n",
            " 37.80703642 21.99021941 37.94741474 41.93522075 38.95222761 35.96188474]\n",
            "Mean Squared Error - Self-Control (Gradient Boosting): 0.049739369711190924\n",
            "[21.65017277 19.85574863 23.8864593  22.10365838 42.0260301  40.0031236\n",
            " 37.35907302 30.0923407  30.80884665 29.37147928 36.11567103 31.6129407\n",
            " 28.91147292 42.0260301  29.79262717 21.2846107  33.29249747 32.992127\n",
            " 29.10175544 30.68885455 29.79262717 32.32451998 41.53325325 35.85713234\n",
            " 37.35907302 22.10365838 37.92831876 42.0260301  39.30722248 36.34378548]\n",
            "Mean Squared Error - Self-Control (Ridge Regression): 3.9914236908669576\n",
            "[24.03595146 22.10643206 25.04204639 24.29549167 39.97449035 38.22859548\n",
            " 35.70350668 30.75900639 31.26273174 30.03049179 34.93236015 31.66833652\n",
            " 29.33673918 39.97449035 30.3196279  23.21457887 32.96538868 32.7539528\n",
            " 29.60886501 32.19886293 30.3196279  31.87369864 39.16447234 35.38708264\n",
            " 35.70350668 24.29549167 37.28862404 39.97449035 38.13780566 35.67186336]\n",
            "Mean Squared Error - Self-Control (Lasso Regression): 5.904157836159897\n",
            "[21.54531081 20.2307947  19.87619317 21.81652016 41.98048819 39.96932649\n",
            " 37.67035308 27.58807576 30.75083055 29.56845569 36.16261881 31.70249295\n",
            " 29.25106665 41.98048819 29.77975595 21.95612896 33.17121024 33.43568988\n",
            " 28.97697061 30.33223655 29.77975595 32.67797898 40.51098056 35.70764238\n",
            " 37.67035308 21.81652016 37.71892948 41.98048819 39.0200384  36.05142069]\n",
            "Mean Squared Error - Self-Control (Stacked Model): 1.2567101489809145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZVZmfDsPkHH"
      },
      "source": [
        "Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Naive Bayes-Gaussian Naive Bayes"
      ],
      "metadata": {
        "id": "4cjHHkkDuXBc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Load your dataset (replace 'your_dataset.csv' with the actual file path)\n",
        "data = pd.read_csv('duplicate1.csv')\n",
        "\n",
        "# Define the columns for each category\n",
        "categories = [\"Well-Being\", \"Sociality\", \"Emotionality\", \"Self-Control\"]\n",
        "\n",
        "# Loop through each category\n",
        "for category in categories:\n",
        "    print(f\"Processing {category} category...\")\n",
        "\n",
        "    # Extract features and labels for the current category\n",
        "    category_column = f\"{category} Classification\"\n",
        "    final_column = f\"Final {category} Value\"\n",
        "\n",
        "    X = data[[category_column]]\n",
        "    Y = data[final_column]\n",
        "\n",
        "    # One-hot encode the categorical feature\n",
        "    encoder = OneHotEncoder(sparse=False, drop='first')\n",
        "    X_encoded = encoder.fit_transform(X)\n",
        "\n",
        "    # Split data into training and testing sets\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X_encoded, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Create a Gaussian Naive Bayes classifier\n",
        "    model = GaussianNB()\n",
        "\n",
        "    # Fit the model to the training data\n",
        "    model.fit(X_train, Y_train)\n",
        "\n",
        "    # Now, you can use the trained model for predictions\n",
        "    Y_pred = model.predict(X_test)\n",
        "\n",
        "    # Evaluate the model's performance using accuracy and other metrics\n",
        "    accuracy = accuracy_score(Y_test, Y_pred)\n",
        "    confusion = confusion_matrix(Y_test, Y_pred)\n",
        "    classification_rep = classification_report(Y_test, Y_pred)\n",
        "\n",
        "    print(f\"Accuracy - {category}: {accuracy}\")\n",
        "    print(f\"Confusion Matrix - {category}:\\n{confusion}\")\n",
        "    print(f\"Classification Report - {category}:\\n{classification_rep}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YMaFeasuYEb",
        "outputId": "3b45ea97-3823-4636-84ce-de25b60ae60f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Well-Being category...\n",
            "Accuracy - Well-Being: 0.1\n",
            "Confusion Matrix - Well-Being:\n",
            "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]]\n",
            "Classification Report - Well-Being:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00         1\n",
            "          16       0.00      0.00      0.00         2\n",
            "          17       0.00      0.00      0.00         1\n",
            "          18       0.00      0.00      0.00         2\n",
            "          20       0.00      0.00      0.00         2\n",
            "          21       0.00      0.00      0.00         2\n",
            "          23       0.00      0.00      0.00         1\n",
            "          24       0.00      0.00      0.00         2\n",
            "          25       0.05      1.00      0.09         1\n",
            "          26       0.00      0.00      0.00         1\n",
            "          27       0.00      0.00      0.00         3\n",
            "          28       0.00      0.00      0.00         2\n",
            "          29       0.00      0.00      0.00         2\n",
            "          30       0.25      1.00      0.40         2\n",
            "          33       0.00      0.00      0.00         2\n",
            "          35       0.00      0.00      0.00         1\n",
            "          36       0.00      0.00      0.00         2\n",
            "          37       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.10        30\n",
            "   macro avg       0.02      0.11      0.03        30\n",
            "weighted avg       0.02      0.10      0.03        30\n",
            "\n",
            "Processing Sociality category...\n",
            "Accuracy - Sociality: 0.06666666666666667\n",
            "Confusion Matrix - Sociality:\n",
            "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0]]\n",
            "Classification Report - Sociality:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           9       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00         1\n",
            "          13       0.00      0.00      0.00         1\n",
            "          17       0.00      0.00      0.00         2\n",
            "          20       0.00      0.00      0.00         3\n",
            "          21       0.00      0.00      0.00         3\n",
            "          22       0.00      0.00      0.00         0\n",
            "          24       0.00      0.00      0.00         2\n",
            "          26       0.00      0.00      0.00         1\n",
            "          27       0.00      0.00      0.00         3\n",
            "          28       0.00      0.00      0.00         2\n",
            "          29       0.00      0.00      0.00         2\n",
            "          30       0.20      1.00      0.33         2\n",
            "          31       0.00      0.00      0.00         3\n",
            "          33       0.00      0.00      0.00         2\n",
            "          36       0.00      0.00      0.00         3\n",
            "\n",
            "    accuracy                           0.07        30\n",
            "   macro avg       0.01      0.06      0.02        30\n",
            "weighted avg       0.01      0.07      0.02        30\n",
            "\n",
            "Processing Emotionality category...\n",
            "Accuracy - Emotionality: 0.1\n",
            "Confusion Matrix - Emotionality:\n",
            "[[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]]\n",
            "Classification Report - Emotionality:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           9       0.00      0.00      0.00         1\n",
            "          11       0.00      0.00      0.00         1\n",
            "          13       0.00      0.00      0.00         0\n",
            "          15       0.00      0.00      0.00         3\n",
            "          17       0.00      0.00      0.00         2\n",
            "          18       0.00      0.00      0.00         1\n",
            "          19       0.00      0.00      0.00         1\n",
            "          20       0.00      0.00      0.00         2\n",
            "          21       0.00      0.00      0.00         2\n",
            "          22       0.08      1.00      0.14         2\n",
            "          23       0.00      0.00      0.00         3\n",
            "          24       0.00      0.00      0.00         3\n",
            "          25       0.00      0.00      0.00         2\n",
            "          26       0.00      0.00      0.00         1\n",
            "          27       0.00      0.00      0.00         3\n",
            "          29       0.00      0.00      0.00         1\n",
            "          30       0.50      1.00      0.67         1\n",
            "          34       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.10        30\n",
            "   macro avg       0.03      0.11      0.04        30\n",
            "weighted avg       0.02      0.10      0.03        30\n",
            "\n",
            "Processing Self-Control category...\n",
            "Accuracy - Self-Control: 0.16666666666666666\n",
            "Confusion Matrix - Self-Control:\n",
            "[[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
            "Classification Report - Self-Control:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          13       0.00      0.00      0.00         1\n",
            "          14       0.50      1.00      0.67         1\n",
            "          15       0.00      0.00      0.00         1\n",
            "          17       0.00      0.00      0.00         1\n",
            "          19       0.00      0.00      0.00         1\n",
            "          21       0.00      0.00      0.00         1\n",
            "          22       0.00      0.00      0.00         4\n",
            "          24       0.00      0.00      0.00         1\n",
            "          26       0.00      0.00      0.00         2\n",
            "          27       0.00      0.00      0.00         3\n",
            "          28       0.21      1.00      0.35         4\n",
            "          29       0.00      0.00      0.00         1\n",
            "          30       0.00      0.00      0.00         2\n",
            "          31       0.00      0.00      0.00         2\n",
            "          32       0.00      0.00      0.00         0\n",
            "          34       0.00      0.00      0.00         2\n",
            "          36       0.00      0.00      0.00         1\n",
            "          39       0.00      0.00      0.00         1\n",
            "          42       0.00      0.00      0.00         1\n",
            "          45       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.17        30\n",
            "   macro avg       0.04      0.10      0.05        30\n",
            "weighted avg       0.04      0.17      0.07        30\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "K-Nearest Neighbour\n",
        "\n"
      ],
      "metadata": {
        "id": "cOaWm10Au6xt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Load your dataset (replace 'your_dataset.csv' with the actual file path)\n",
        "data = pd.read_csv('duplicate1.csv')\n",
        "\n",
        "# Define the columns for each category\n",
        "categories = [\"Well-Being\", \"Sociality\", \"Emotionality\", \"Self-Control\"]\n",
        "\n",
        "# Loop through each category\n",
        "for category in categories:\n",
        "    print(f\"Processing {category} category...\")\n",
        "\n",
        "    # Extract features and labels for the current category\n",
        "    category_column = f\"{category} Classification\"\n",
        "    final_column = f\"Final {category} Value\"\n",
        "\n",
        "    X = data[[category_column]]\n",
        "    Y = data[final_column]\n",
        "\n",
        "    # One-hot encode the categorical feature\n",
        "    encoder = OneHotEncoder(sparse=False, drop='first')\n",
        "    X_encoded = encoder.fit_transform(X)\n",
        "\n",
        "    # Split data into training and testing sets\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X_encoded, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Create a K-NN classifier (you can adjust the number of neighbors as needed)\n",
        "    model = KNeighborsClassifier(n_neighbors=5)  # Change the number of neighbors as needed\n",
        "\n",
        "    # Fit the model to the training data\n",
        "    model.fit(X_train, Y_train)\n",
        "\n",
        "    # Now, you can use the trained model for predictions\n",
        "    Y_pred = model.predict(X_test)\n",
        "\n",
        "    # Evaluate the model's performance using accuracy and other metrics\n",
        "    accuracy = accuracy_score(Y_test, Y_pred)\n",
        "    confusion = confusion_matrix(Y_test, Y_pred)\n",
        "    classification_rep = classification_report(Y_test, Y_pred)\n",
        "\n",
        "    print(f\"Accuracy - {category}: {accuracy}\")\n",
        "    print(f\"Confusion Matrix - {category}:\\n{confusion}\")\n",
        "    print(f\"Classification Report - {category}:\\n{classification_rep}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQCr1Rrzu2AU",
        "outputId": "99e4a963-b7c2-406b-ab70-00f84aeab4c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Well-Being category...\n",
            "Accuracy - Well-Being: 0.13333333333333333\n",
            "Confusion Matrix - Well-Being:\n",
            "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]]\n",
            "Classification Report - Well-Being:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00         1\n",
            "          16       0.00      0.00      0.00         2\n",
            "          17       0.00      0.00      0.00         1\n",
            "          18       0.10      1.00      0.17         2\n",
            "          20       0.00      0.00      0.00         2\n",
            "          21       0.00      0.00      0.00         2\n",
            "          23       0.00      0.00      0.00         1\n",
            "          24       0.00      0.00      0.00         2\n",
            "          25       0.00      0.00      0.00         1\n",
            "          26       0.00      0.00      0.00         1\n",
            "          27       0.00      0.00      0.00         3\n",
            "          28       0.00      0.00      0.00         2\n",
            "          29       0.00      0.00      0.00         2\n",
            "          30       0.25      1.00      0.40         2\n",
            "          33       0.00      0.00      0.00         2\n",
            "          35       0.00      0.00      0.00         1\n",
            "          36       0.00      0.00      0.00         2\n",
            "          37       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.13        30\n",
            "   macro avg       0.02      0.11      0.03        30\n",
            "weighted avg       0.02      0.13      0.04        30\n",
            "\n",
            "Processing Sociality category...\n",
            "Accuracy - Sociality: 0.06666666666666667\n",
            "Confusion Matrix - Sociality:\n",
            "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0]]\n",
            "Classification Report - Sociality:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           9       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00         1\n",
            "          13       0.00      0.00      0.00         1\n",
            "          17       0.00      0.00      0.00         2\n",
            "          18       0.00      0.00      0.00         0\n",
            "          20       0.00      0.00      0.00         3\n",
            "          21       0.00      0.00      0.00         3\n",
            "          24       0.00      0.00      0.00         2\n",
            "          26       0.00      0.00      0.00         1\n",
            "          27       0.00      0.00      0.00         3\n",
            "          28       0.00      0.00      0.00         2\n",
            "          29       0.00      0.00      0.00         2\n",
            "          30       0.20      1.00      0.33         2\n",
            "          31       0.00      0.00      0.00         3\n",
            "          33       0.00      0.00      0.00         2\n",
            "          36       0.00      0.00      0.00         3\n",
            "\n",
            "    accuracy                           0.07        30\n",
            "   macro avg       0.01      0.06      0.02        30\n",
            "weighted avg       0.01      0.07      0.02        30\n",
            "\n",
            "Processing Emotionality category...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy - Emotionality: 0.06666666666666667\n",
            "Confusion Matrix - Emotionality:\n",
            "[[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]]\n",
            "Classification Report - Emotionality:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           9       0.00      0.00      0.00         1\n",
            "          11       0.00      0.00      0.00         1\n",
            "          13       0.00      0.00      0.00         0\n",
            "          15       0.00      0.00      0.00         3\n",
            "          17       0.00      0.00      0.00         2\n",
            "          18       0.04      1.00      0.07         1\n",
            "          19       0.00      0.00      0.00         1\n",
            "          20       0.00      0.00      0.00         2\n",
            "          21       0.00      0.00      0.00         2\n",
            "          22       0.00      0.00      0.00         2\n",
            "          23       0.00      0.00      0.00         3\n",
            "          24       0.00      0.00      0.00         3\n",
            "          25       0.00      0.00      0.00         2\n",
            "          26       0.00      0.00      0.00         1\n",
            "          27       0.00      0.00      0.00         3\n",
            "          29       0.00      0.00      0.00         1\n",
            "          30       0.50      1.00      0.67         1\n",
            "          34       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.07        30\n",
            "   macro avg       0.03      0.11      0.04        30\n",
            "weighted avg       0.02      0.07      0.02        30\n",
            "\n",
            "Processing Self-Control category...\n",
            "Accuracy - Self-Control: 0.1\n",
            "Confusion Matrix - Self-Control:\n",
            "[[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
            "Classification Report - Self-Control:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          13       0.00      0.00      0.00         1\n",
            "          14       0.50      1.00      0.67         1\n",
            "          15       0.00      0.00      0.00         1\n",
            "          17       0.00      0.00      0.00         1\n",
            "          18       0.00      0.00      0.00         0\n",
            "          19       0.00      0.00      0.00         1\n",
            "          21       0.00      0.00      0.00         1\n",
            "          22       0.00      0.00      0.00         4\n",
            "          24       0.00      0.00      0.00         1\n",
            "          26       0.00      0.00      0.00         2\n",
            "          27       0.00      0.00      0.00         3\n",
            "          28       0.00      0.00      0.00         4\n",
            "          29       0.00      0.00      0.00         1\n",
            "          30       0.25      1.00      0.40         2\n",
            "          31       0.00      0.00      0.00         2\n",
            "          34       0.00      0.00      0.00         2\n",
            "          36       0.00      0.00      0.00         1\n",
            "          39       0.00      0.00      0.00         1\n",
            "          42       0.00      0.00      0.00         1\n",
            "          45       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.10        30\n",
            "   macro avg       0.04      0.10      0.05        30\n",
            "weighted avg       0.03      0.10      0.05        30\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Support Vector Machine"
      ],
      "metadata": {
        "id": "kc05O44VA1IT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Load your dataset (replace 'your_dataset.csv' with the actual file path)\n",
        "data = pd.read_csv('/content/samp_file.csv')\n",
        "\n",
        "# Define the columns for each category\n",
        "categories = [\"Well-Being\", \"Sociality\", \"Emotionality\", \"Self-Control\"]\n",
        "\n",
        "# Loop through each category\n",
        "for category in categories:\n",
        "    print(f\"Processing {category} category...\")\n",
        "\n",
        "    # Extract features and labels for the current category\n",
        "    category_column = f\"{category} Classification\"\n",
        "    final_column = f\"Final {category} Value\"\n",
        "\n",
        "    X = data[[category_column]]\n",
        "    Y = data[final_column]\n",
        "\n",
        "    # One-hot encode the categorical feature\n",
        "    encoder = OneHotEncoder(sparse=False, drop='first')\n",
        "    X_encoded = encoder.fit_transform(X)\n",
        "\n",
        "    # Split data into training and testing sets\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X_encoded, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Create an SVM classifier with a linear kernel (you can adjust the kernel and other parameters as needed)\n",
        "    model = SVC(kernel='linear')\n",
        "\n",
        "    # Fit the model to the training data\n",
        "    model.fit(X_train, Y_train)\n",
        "\n",
        "    # Now, you can use the trained model for predictions\n",
        "    Y_pred = model.predict(X_test)\n",
        "\n",
        "    # Evaluate the model's performance using accuracy and other metrics\n",
        "    accuracy = accuracy_score(Y_test, Y_pred)\n",
        "    confusion = confusion_matrix(Y_test, Y_pred)\n",
        "    classification_rep = classification_report(Y_test, Y_pred)\n",
        "\n",
        "    print(f\"Accuracy - {category}: {accuracy}\")\n",
        "    print(f\"Confusion Matrix - {category}:\\n{confusion}\")\n",
        "    print(f\"Classification Report - {category}:\\n{classification_rep}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FO9B1zlQ_iJJ",
        "outputId": "df96bd15-1c28-43df-9bc4-bb8634cd233a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Well-Being category...\n",
            "Accuracy - Well-Being: 0.03333333333333333\n",
            "Confusion Matrix - Well-Being:\n",
            "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]]\n",
            "Classification Report - Well-Being:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          12       0.00      0.00      0.00         1\n",
            "          16       0.00      0.00      0.00         2\n",
            "          17       0.00      0.00      0.00         1\n",
            "          18       0.00      0.00      0.00         2\n",
            "          20       0.00      0.00      0.00         2\n",
            "          21       0.00      0.00      0.00         2\n",
            "          23       0.00      0.00      0.00         1\n",
            "          24       0.00      0.00      0.00         2\n",
            "          25       0.05      1.00      0.09         1\n",
            "          26       0.00      0.00      0.00         1\n",
            "          27       0.00      0.00      0.00         3\n",
            "          28       0.00      0.00      0.00         2\n",
            "          29       0.00      0.00      0.00         2\n",
            "          30       0.00      0.00      0.00         2\n",
            "          31       0.00      0.00      0.00         0\n",
            "          33       0.00      0.00      0.00         2\n",
            "          35       0.00      0.00      0.00         1\n",
            "          36       0.00      0.00      0.00         2\n",
            "          37       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.03        30\n",
            "   macro avg       0.00      0.05      0.00        30\n",
            "weighted avg       0.00      0.03      0.00        30\n",
            "\n",
            "Processing Sociality category...\n",
            "Accuracy - Sociality: 0.06666666666666667\n",
            "Confusion Matrix - Sociality:\n",
            "[[0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 2 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 3 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 3 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 2 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 3 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 2 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 2 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 2 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 3 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 2 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 3 0 0 0]]\n",
            "Classification Report - Sociality:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          12       0.00      0.00      0.00         1\n",
            "          13       0.00      0.00      0.00         1\n",
            "          17       0.00      0.00      0.00         2\n",
            "          20       0.00      0.00      0.00         3\n",
            "          21       0.00      0.00      0.00         3\n",
            "          22       0.00      0.00      0.00         0\n",
            "          24       0.00      0.00      0.00         2\n",
            "          26       0.00      0.00      0.00         1\n",
            "          27       0.00      0.00      0.00         3\n",
            "          28       0.00      0.00      0.00         2\n",
            "          29       0.00      0.00      0.00         2\n",
            "          30       0.17      1.00      0.29         2\n",
            "          31       0.00      0.00      0.00         3\n",
            "          33       0.00      0.00      0.00         2\n",
            "          36       0.00      0.00      0.00         3\n",
            "\n",
            "    accuracy                           0.07        30\n",
            "   macro avg       0.01      0.07      0.02        30\n",
            "weighted avg       0.01      0.07      0.02        30\n",
            "\n",
            "Processing Emotionality category...\n",
            "Accuracy - Emotionality: 0.1\n",
            "Confusion Matrix - Emotionality:\n",
            "[[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]]\n",
            "Classification Report - Emotionality:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           9       0.00      0.00      0.00         1\n",
            "          11       0.00      0.00      0.00         1\n",
            "          13       0.00      0.00      0.00         0\n",
            "          15       0.00      0.00      0.00         3\n",
            "          17       0.00      0.00      0.00         2\n",
            "          18       0.00      0.00      0.00         1\n",
            "          19       0.00      0.00      0.00         1\n",
            "          20       0.00      0.00      0.00         2\n",
            "          21       0.00      0.00      0.00         2\n",
            "          22       0.08      1.00      0.14         2\n",
            "          23       0.00      0.00      0.00         3\n",
            "          24       0.00      0.00      0.00         3\n",
            "          25       0.00      0.00      0.00         2\n",
            "          26       0.00      0.00      0.00         1\n",
            "          27       0.00      0.00      0.00         3\n",
            "          29       0.00      0.00      0.00         1\n",
            "          30       0.50      1.00      0.67         1\n",
            "          34       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.10        30\n",
            "   macro avg       0.03      0.11      0.04        30\n",
            "weighted avg       0.02      0.10      0.03        30\n",
            "\n",
            "Processing Self-Control category...\n",
            "Accuracy - Self-Control: 0.23333333333333334\n",
            "Confusion Matrix - Self-Control:\n",
            "[[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
            "Classification Report - Self-Control:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          13       0.00      0.00      0.00         1\n",
            "          14       0.50      1.00      0.67         1\n",
            "          15       0.00      0.00      0.00         1\n",
            "          17       0.00      0.00      0.00         1\n",
            "          19       0.00      0.00      0.00         1\n",
            "          21       0.00      0.00      0.00         1\n",
            "          22       0.00      0.00      0.00         4\n",
            "          24       0.00      0.00      0.00         1\n",
            "          26       0.00      0.00      0.00         2\n",
            "          27       0.00      0.00      0.00         3\n",
            "          28       0.21      1.00      0.35         4\n",
            "          29       0.00      0.00      0.00         1\n",
            "          30       0.00      0.00      0.00         2\n",
            "          31       0.00      0.00      0.00         2\n",
            "          34       0.25      1.00      0.40         2\n",
            "          36       0.00      0.00      0.00         1\n",
            "          39       0.00      0.00      0.00         1\n",
            "          42       0.00      0.00      0.00         1\n",
            "          45       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.23        30\n",
            "   macro avg       0.05      0.16      0.07        30\n",
            "weighted avg       0.06      0.23      0.10        30\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Classifier-Dummy Classifier"
      ],
      "metadata": {
        "id": "ECwp5UgpB04w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Load your dataset (replace 'your_dataset.csv' with the actual file path)\n",
        "data = pd.read_csv('duplicate1.csv')\n",
        "\n",
        "# Define the columns for each category\n",
        "categories = [\"Well-Being\", \"Sociality\", \"Emotionality\", \"Self-Control\"]\n",
        "\n",
        "# Loop through each category\n",
        "for category in categories:\n",
        "    print(f\"Processing {category} category...\")\n",
        "\n",
        "    # Extract features and labels for the current category\n",
        "    category_column = f\"{category} Classification\"\n",
        "    final_column = f\"Final {category} Value\"\n",
        "\n",
        "    X = data[[category_column]]\n",
        "    Y = data[final_column]\n",
        "\n",
        "    # One-hot encode the categorical feature\n",
        "    encoder = OneHotEncoder(sparse=False, drop='first')\n",
        "    X_encoded = encoder.fit_transform(X)\n",
        "\n",
        "    # Split data into training and testing sets\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X_encoded, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Create a random classifier with a strategy of 'uniform' (random predictions)\n",
        "    model = DummyClassifier(strategy='uniform')\n",
        "\n",
        "    # Fit the model to the training data (no actual training is done for a random classifier)\n",
        "    model.fit(X_train, Y_train)\n",
        "\n",
        "    # Now, you can use the trained model for predictions (which are random)\n",
        "    Y_pred = model.predict(X_test)\n",
        "\n",
        "    # Evaluate the model's performance using accuracy and other metrics\n",
        "    accuracy = accuracy_score(Y_test, Y_pred)\n",
        "    confusion = confusion_matrix(Y_test, Y_pred)\n",
        "    classification_rep = classification_report(Y_test, Y_pred)\n",
        "\n",
        "    print(f\"Accuracy - {category}: {accuracy}\")\n",
        "    print(f\"Confusion Matrix - {category}:\\n{confusion}\")\n",
        "    print(f\"Classification Report - {category}:\\n{classification_rep}\")\n"
      ],
      "metadata": {
        "id": "Qnt0ol1IB3l4",
        "outputId": "5eeb8b6b-537b-42a3-a1f1-7f92c4528819",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Well-Being category...\n",
            "Accuracy - Well-Being: 0.0\n",
            "Confusion Matrix - Well-Being:\n",
            "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
            " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
            "Classification Report - Well-Being:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          11       0.00      0.00      0.00       0.0\n",
            "          12       0.00      0.00      0.00       1.0\n",
            "          14       0.00      0.00      0.00       0.0\n",
            "          15       0.00      0.00      0.00       0.0\n",
            "          16       0.00      0.00      0.00       2.0\n",
            "          17       0.00      0.00      0.00       1.0\n",
            "          18       0.00      0.00      0.00       2.0\n",
            "          19       0.00      0.00      0.00       0.0\n",
            "          20       0.00      0.00      0.00       2.0\n",
            "          21       0.00      0.00      0.00       2.0\n",
            "          23       0.00      0.00      0.00       1.0\n",
            "          24       0.00      0.00      0.00       2.0\n",
            "          25       0.00      0.00      0.00       1.0\n",
            "          26       0.00      0.00      0.00       1.0\n",
            "          27       0.00      0.00      0.00       3.0\n",
            "          28       0.00      0.00      0.00       2.0\n",
            "          29       0.00      0.00      0.00       2.0\n",
            "          30       0.00      0.00      0.00       2.0\n",
            "          32       0.00      0.00      0.00       0.0\n",
            "          33       0.00      0.00      0.00       2.0\n",
            "          34       0.00      0.00      0.00       0.0\n",
            "          35       0.00      0.00      0.00       1.0\n",
            "          36       0.00      0.00      0.00       2.0\n",
            "          37       0.00      0.00      0.00       1.0\n",
            "          39       0.00      0.00      0.00       0.0\n",
            "          40       0.00      0.00      0.00       0.0\n",
            "          41       0.00      0.00      0.00       0.0\n",
            "\n",
            "    accuracy                           0.00      30.0\n",
            "   macro avg       0.00      0.00      0.00      30.0\n",
            "weighted avg       0.00      0.00      0.00      30.0\n",
            "\n",
            "Processing Sociality category...\n",
            "Accuracy - Sociality: 0.03333333333333333\n",
            "Confusion Matrix - Sociality:\n",
            "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
            "Classification Report - Sociality:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           9       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00         1\n",
            "          13       0.00      0.00      0.00         1\n",
            "          14       0.00      0.00      0.00         0\n",
            "          16       0.00      0.00      0.00         0\n",
            "          17       0.00      0.00      0.00         2\n",
            "          18       0.00      0.00      0.00         0\n",
            "          19       0.00      0.00      0.00         0\n",
            "          20       0.00      0.00      0.00         3\n",
            "          21       0.00      0.00      0.00         3\n",
            "          22       0.00      0.00      0.00         0\n",
            "          23       0.00      0.00      0.00         0\n",
            "          24       0.00      0.00      0.00         2\n",
            "          25       0.00      0.00      0.00         0\n",
            "          26       1.00      1.00      1.00         1\n",
            "          27       0.00      0.00      0.00         3\n",
            "          28       0.00      0.00      0.00         2\n",
            "          29       0.00      0.00      0.00         2\n",
            "          30       0.00      0.00      0.00         2\n",
            "          31       0.00      0.00      0.00         3\n",
            "          32       0.00      0.00      0.00         0\n",
            "          33       0.00      0.00      0.00         2\n",
            "          34       0.00      0.00      0.00         0\n",
            "          35       0.00      0.00      0.00         0\n",
            "          36       0.00      0.00      0.00         3\n",
            "          38       0.00      0.00      0.00         0\n",
            "          39       0.00      0.00      0.00         0\n",
            "          40       0.00      0.00      0.00         0\n",
            "          45       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.03        30\n",
            "   macro avg       0.03      0.03      0.03        30\n",
            "weighted avg       0.03      0.03      0.03        30\n",
            "\n",
            "Processing Emotionality category...\n",
            "Accuracy - Emotionality: 0.03333333333333333\n",
            "Confusion Matrix - Emotionality:\n",
            "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0]\n",
            " [0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
            "Classification Report - Emotionality:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           7       0.00      0.00      0.00         0\n",
            "           9       0.00      0.00      0.00         1\n",
            "          11       0.00      0.00      0.00         1\n",
            "          13       0.00      0.00      0.00         0\n",
            "          15       0.00      0.00      0.00         3\n",
            "          16       0.00      0.00      0.00         0\n",
            "          17       0.00      0.00      0.00         2\n",
            "          18       0.00      0.00      0.00         1\n",
            "          19       0.00      0.00      0.00         1\n",
            "          20       0.00      0.00      0.00         2\n",
            "          21       0.00      0.00      0.00         2\n",
            "          22       0.00      0.00      0.00         2\n",
            "          23       0.00      0.00      0.00         3\n",
            "          24       0.00      0.00      0.00         3\n",
            "          25       0.33      0.50      0.40         2\n",
            "          26       0.00      0.00      0.00         1\n",
            "          27       0.00      0.00      0.00         3\n",
            "          29       0.00      0.00      0.00         1\n",
            "          30       0.00      0.00      0.00         1\n",
            "          31       0.00      0.00      0.00         0\n",
            "          32       0.00      0.00      0.00         0\n",
            "          33       0.00      0.00      0.00         0\n",
            "          34       0.00      0.00      0.00         1\n",
            "          35       0.00      0.00      0.00         0\n",
            "          37       0.00      0.00      0.00         0\n",
            "          41       0.00      0.00      0.00         0\n",
            "          42       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.03        30\n",
            "   macro avg       0.01      0.02      0.01        30\n",
            "weighted avg       0.02      0.03      0.03        30\n",
            "\n",
            "Processing Self-Control category...\n",
            "Accuracy - Self-Control: 0.03333333333333333\n",
            "Confusion Matrix - Self-Control:\n",
            "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 2 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 2 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
            "Classification Report - Self-Control:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          13       0.00      0.00      0.00         1\n",
            "          14       0.00      0.00      0.00         1\n",
            "          15       0.00      0.00      0.00         1\n",
            "          16       0.00      0.00      0.00         0\n",
            "          17       0.00      0.00      0.00         1\n",
            "          18       0.00      0.00      0.00         0\n",
            "          19       0.00      0.00      0.00         1\n",
            "          21       0.00      0.00      0.00         1\n",
            "          22       0.00      0.00      0.00         4\n",
            "          23       0.00      0.00      0.00         0\n",
            "          24       0.00      0.00      0.00         1\n",
            "          25       0.00      0.00      0.00         0\n",
            "          26       0.00      0.00      0.00         2\n",
            "          27       0.00      0.00      0.00         3\n",
            "          28       0.00      0.00      0.00         4\n",
            "          29       0.00      0.00      0.00         1\n",
            "          30       0.00      0.00      0.00         2\n",
            "          31       0.00      0.00      0.00         2\n",
            "          32       0.00      0.00      0.00         0\n",
            "          34       0.00      0.00      0.00         2\n",
            "          35       0.00      0.00      0.00         0\n",
            "          36       0.00      0.00      0.00         1\n",
            "          37       0.00      0.00      0.00         0\n",
            "          38       0.00      0.00      0.00         0\n",
            "          39       0.00      0.00      0.00         1\n",
            "          41       0.00      0.00      0.00         0\n",
            "          42       0.33      1.00      0.50         1\n",
            "          45       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.03        30\n",
            "   macro avg       0.01      0.04      0.02        30\n",
            "weighted avg       0.01      0.03      0.02        30\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming the uploaded CSV file is named 'example.csv'\n",
        "data = pd.read_csv('duplicate1 (1).csv')\n"
      ],
      "metadata": {
        "id": "qL7Putb1c2gu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming your data is stored in a DataFrame called 'data'\n",
        "\n",
        "# Define the classification thresholds for all categories\n",
        "high_threshold = 35\n",
        "medium_threshold_low = 29\n",
        "medium_threshold_high = 30\n",
        "\n",
        "# Function to classify values\n",
        "def classify_value(value):\n",
        "    if value >= high_threshold:\n",
        "        return 'High'\n",
        "    elif value >= medium_threshold_low and value <= medium_threshold_high:\n",
        "        return 'Medium'\n",
        "    else:\n",
        "        return 'Low'\n",
        "\n",
        "# Apply the classification function to the 'Final Well-Being Value' column\n",
        "data['Well-Being Classification'] = data['Final Well-Being Value'].apply(classify_value)\n",
        "\n",
        "# Apply the classification function to the 'Final Sociality Value' column\n",
        "data['Sociality Classification'] = data['Final Sociality Value'].apply(classify_value)\n",
        "\n",
        "# Apply the classification function to the 'Final Emotionality Value' column\n",
        "data['Emotionality Classification'] = data['Final Emotionality Value'].apply(classify_value)\n",
        "\n",
        "# Apply the classification function to the 'Final Self-Control Value' column\n",
        "data['Self-Control Classification'] = data['Final Self-Control Value'].apply(classify_value)\n",
        "\n",
        "# You now have classifications for all categories in your DataFrame\n"
      ],
      "metadata": {
        "id": "LaX5ZOLPdrNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first few rows of the DataFrame\n",
        "print(data.head())\n"
      ],
      "metadata": {
        "id": "E4th4aGglxIT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fa91bc8-5950-485c-d58a-e45a17d6b74e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             Timestamp           Full Name  Age  Gender  \\\n",
            "0  2023-09-07 19:46:34          Tharanikha   22  Female   \n",
            "1  2023-09-07 19:47:43             Jothika   22  Female   \n",
            "2  2023-09-07 19:49:15            Nishanth   27    Male   \n",
            "3  2023-09-07 20:02:12            Priyanka   22  Female   \n",
            "4  2023-09-07 20:40:25  M.KIRUTHIGAI MEENA   22  Female   \n",
            "\n",
            "                    Email Address                         Company  \\\n",
            "0      tharanikha@student.tce.edu  Cognizant technology solutions   \n",
            "1       jothikatamk0501@gmail.com               Stock markets NSE   \n",
            "2         nisanthvasu11@gmail.com                Stock market NSE   \n",
            "3  priyankachezhian2000@gmail.com                       Cognizant   \n",
            "4       kiruthigaimeena@gmail.com                       Caratlane   \n",
            "\n",
            "                     Position        Experience Consent  wb_q1  ...  emo_q10  \\\n",
            "0  Programmer analyst trainee         1-2 years     Yes      4  ...        3   \n",
            "1                      Trader  Less than 1 year     Yes      4  ...        3   \n",
            "2                Swing trader         1-2 years     Yes      4  ...        3   \n",
            "3          Programmer Analyst         1-2 years     Yes      3  ...        3   \n",
            "4          Software Developer         1-2 years     Yes      3  ...        3   \n",
            "\n",
            "   wb_10  Final Well-Being Value  Final Sociality Value  \\\n",
            "0      3                    31.0                   35.0   \n",
            "1      2                    30.0                   36.0   \n",
            "2      4                    32.0                   35.0   \n",
            "3      3                    30.0                   30.0   \n",
            "4      3                    33.0                   33.0   \n",
            "\n",
            "   Final Emotionality Value  Final Self-Control Value  \\\n",
            "0                      30.0                      32.0   \n",
            "1                      33.0                      31.0   \n",
            "2                      34.0                      34.0   \n",
            "3                      30.0                      30.0   \n",
            "4                      33.0                      32.0   \n",
            "\n",
            "   Well-Being Classification  Sociality Classification  \\\n",
            "0                        Low                      High   \n",
            "1                     Medium                      High   \n",
            "2                        Low                      High   \n",
            "3                     Medium                    Medium   \n",
            "4                        Low                       Low   \n",
            "\n",
            "   Emotionality Classification  Self-Control Classification  \n",
            "0                       Medium                          Low  \n",
            "1                          Low                          Low  \n",
            "2                          Low                          Low  \n",
            "3                       Medium                       Medium  \n",
            "4                          Low                          Low  \n",
            "\n",
            "[5 rows x 57 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display specific columns (e.g., classification columns)\n",
        "print(data[['Well-Being Classification', 'Sociality Classification', 'Emotionality Classification', 'Self-Control Classification']])\n"
      ],
      "metadata": {
        "id": "aXJd50eUl4eB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fac38c0-2713-413d-c37d-aa26389fc34a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Well-Being Classification Sociality Classification  \\\n",
            "0                         Low                     High   \n",
            "1                      Medium                     High   \n",
            "2                         Low                     High   \n",
            "3                      Medium                   Medium   \n",
            "4                         Low                      Low   \n",
            "..                        ...                      ...   \n",
            "145                       Low                     High   \n",
            "146                       Low                   Medium   \n",
            "147                      High                      Low   \n",
            "148                       Low                      Low   \n",
            "149                    Medium                      Low   \n",
            "\n",
            "    Emotionality Classification Self-Control Classification  \n",
            "0                        Medium                         Low  \n",
            "1                           Low                         Low  \n",
            "2                           Low                         Low  \n",
            "3                        Medium                      Medium  \n",
            "4                           Low                         Low  \n",
            "..                          ...                         ...  \n",
            "145                         Low                         Low  \n",
            "146                         Low                         Low  \n",
            "147                      Medium                        High  \n",
            "148                         Low                         Low  \n",
            "149                         Low                      Medium  \n",
            "\n",
            "[150 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming your DataFrame is named 'data' and you want to save it as a CSV file\n",
        "file_path = '/content/output_file.csv'\n",
        "\n",
        "# Save the DataFrame as a CSV file\n",
        "data.to_csv(file_path, index=False)\n",
        "\n",
        "print(f\"DataFrame saved as CSV at '{file_path}'\")\n"
      ],
      "metadata": {
        "id": "_lNw8ND5mbrH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1271d73-c3d2-47fc-d527-4b70e3d52e27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved as CSV at '/content/output_file.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression Classifier"
      ],
      "metadata": {
        "id": "HFX-KR2dry59"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming the uploaded CSV file is named 'example.csv'\n",
        "data = pd.read_csv('/content/samp_file.csv')\n"
      ],
      "metadata": {
        "id": "eLdrNFFIncFU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "7949ce92-7957-4928-ce95-db1f06e0e53d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/samp_file.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-870c4c40c266>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Assuming the uploaded CSV file is named 'example.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/samp_file.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1448\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1706\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    861\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    864\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/samp_file.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Sample data\n",
        "data = pd.DataFrame({\n",
        "    'Final Well-Being Value': [33, 40, 25, 29, 36],\n",
        "    'Final Sociality Value': [28, 31, 35, 22, 40],\n",
        "    'Final Emotionality Value': [32, 27, 29, 31, 38],\n",
        "    'Final Self-Control Value': [20, 36, 40, 28, 25]\n",
        "})\n",
        "\n",
        "# Define the classification thresholds for all categories\n",
        "high_threshold = 35\n",
        "medium_threshold_low = 29\n",
        "medium_threshold_high = 30\n",
        "\n",
        "# Function to classify values\n",
        "def classify_value(value, high_threshold, medium_threshold_low, medium_threshold_high):\n",
        "    if value >= high_threshold:\n",
        "        return 'High'\n",
        "    elif value >= medium_threshold_low and value <= medium_threshold_high:\n",
        "        return 'Medium'\n",
        "    else:\n",
        "        return 'Low'\n",
        "\n",
        "# Columns for which you want to create classifications\n",
        "columns_to_classify = ['Final Well-Being Value', 'Final Sociality Value', 'Final Emotionality Value', 'Final Self-Control Value']\n",
        "\n",
        "# Create a dictionary to store classification results and logistic regression models\n",
        "classifications = {}\n",
        "logistic_regression_models = {}\n",
        "\n",
        "# Label encode the classifications\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "for column in columns_to_classify:\n",
        "    # Create classification for the specified column\n",
        "    data[column + ' Classification'] = data[column].apply(classify_value, args=(high_threshold, medium_threshold_low, medium_threshold_high))\n",
        "\n",
        "    # Label encode the classifications\n",
        "    data[column + ' Classification'] = label_encoder.fit_transform(data[column + ' Classification'])\n",
        "\n",
        "    # Create and fit a logistic regression model to predict these classifications\n",
        "    classifier = LogisticRegression()\n",
        "    X = data[[column]].values\n",
        "    y = data[column + ' Classification'].values\n",
        "    classifier.fit(X, y)\n",
        "\n",
        "    # Store the logistic regression model and its associated column\n",
        "    classifications[column] = data[column + ' Classification']\n",
        "    logistic_regression_models[column] = classifier\n",
        "\n",
        "# Print the classifications and logistic regression models\n",
        "for column in columns_to_classify:\n",
        "    print(f'Column: {column}')\n",
        "    print(data[column + ' Classification'])\n",
        "    print(f'Logistic Regression Model for {column}: {logistic_regression_models[column]}\\n')\n",
        "\n",
        "    from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data[columns_to_classify], data[columns_to_classify].values, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a dictionary to store accuracy scores\n",
        "accuracy_scores = {}\n",
        "\n",
        "for column in columns_to_classify:\n",
        "    # Fit the classifier on the training data\n",
        "    decision_tree_classifiers[column].fit(X_train[[column]], y_train[:, 0])\n",
        "\n",
        "    # Make predictions on the test data\n",
        "    y_pred = decision_tree_classifiers[column].predict(X_test[[column]])\n",
        "\n",
        "    # Calculate the accuracy score\n",
        "    accuracy = accuracy_score(y_test[:, 0], y_pred)\n",
        "\n",
        "    # Store the accuracy score\n",
        "    accuracy_scores[column] = accuracy\n",
        "\n",
        "# Print the accuracy scores\n",
        "for column in columns_to_classify:\n",
        "    print(f'Accuracy - {column}: {accuracy_scores[column]:.2f}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilXn982TOTUG",
        "outputId": "ec38d72d-6800-449b-af2a-6db692a688c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column: Final Well-Being Value\n",
            "0    1\n",
            "1    0\n",
            "2    1\n",
            "3    2\n",
            "4    0\n",
            "Name: Final Well-Being Value Classification, dtype: int64\n",
            "Logistic Regression Model for Final Well-Being Value: LogisticRegression()\n",
            "\n",
            "Column: Final Sociality Value\n",
            "0    1\n",
            "1    1\n",
            "2    0\n",
            "3    1\n",
            "4    0\n",
            "Name: Final Sociality Value Classification, dtype: int64\n",
            "Logistic Regression Model for Final Sociality Value: LogisticRegression()\n",
            "\n",
            "Column: Final Emotionality Value\n",
            "0    1\n",
            "1    1\n",
            "2    2\n",
            "3    1\n",
            "4    0\n",
            "Name: Final Emotionality Value Classification, dtype: int64\n",
            "Logistic Regression Model for Final Emotionality Value: LogisticRegression()\n",
            "\n",
            "Column: Final Self-Control Value\n",
            "0    1\n",
            "1    0\n",
            "2    0\n",
            "3    1\n",
            "4    1\n",
            "Name: Final Self-Control Value Classification, dtype: int64\n",
            "Logistic Regression Model for Final Self-Control Value: LogisticRegression()\n",
            "\n",
            "Accuracy - Final Well-Being Value: 0.00\n",
            "Accuracy - Final Sociality Value: 0.00\n",
            "Accuracy - Final Emotionality Value: 0.00\n",
            "Accuracy - Final Self-Control Value: 0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Desicion Tree Classifier"
      ],
      "metadata": {
        "id": "v4RWphB5r5Sc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming the uploaded CSV file is named 'example.csv'\n",
        "data = pd.read_csv('/content/samp_file.csv')\n"
      ],
      "metadata": {
        "id": "cxmfxC5AmzGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "\n",
        "\n",
        "# Sample data\n",
        "data = pd.DataFrame({\n",
        "    'Final Well-Being Value': [33, 40, 25, 29, 36],\n",
        "    'Final Sociality Value': [28, 31, 35, 22, 40],\n",
        "    'Final Emotionality Value': [32, 27, 29, 31, 38],\n",
        "    'Final Self-Control Value': [20, 36, 40, 28, 25]\n",
        "})\n",
        "\n",
        "# Define the classification thresholds for all categories\n",
        "high_threshold = 35\n",
        "medium_threshold_low = 29\n",
        "medium_threshold_high = 30\n",
        "\n",
        "# Function to classify values\n",
        "def classify_value(value, high_threshold, medium_threshold_low, medium_threshold_high):\n",
        "    if value >= high_threshold:\n",
        "        return 'High'\n",
        "    elif value >= medium_threshold_low and value <= medium_threshold_high:\n",
        "        return 'Medium'\n",
        "    else:\n",
        "        return 'Low'\n",
        "\n",
        "# Columns for which you want to create classifications\n",
        "columns_to_classify = ['Final Well-Being Value', 'Final Sociality Value', 'Final Emotionality Value', 'Final Self-Control Value']\n",
        "\n",
        "# Create a dictionary to store classification results and decision tree classifiers\n",
        "classifications = {}\n",
        "decision_tree_classifiers = {}\n",
        "\n",
        "for column in columns_to_classify:\n",
        "    # Create classification for the specified column\n",
        "    data[column + ' Classification'] = data[column].apply(classify_value, args=(high_threshold, medium_threshold_low, medium_threshold_high))\n",
        "\n",
        "    # Create and fit a decision tree classifier to predict these classifications\n",
        "    classifier = DecisionTreeClassifier()\n",
        "    X = data[[column]].values\n",
        "    y = data[column + ' Classification'].values\n",
        "    classifier.fit(X, y)\n",
        "\n",
        "    # Store the classifier and its associated column\n",
        "    classifications[column] = data[column + ' Classification']\n",
        "    decision_tree_classifiers[column] = classifier\n",
        "\n",
        "# Print the classifications and decision tree classifiers\n",
        "for column in columns_to_classify:\n",
        "    print(f'Column: {column}')\n",
        "    print(data[column + ' Classification'])\n",
        "    print(f'Decision Tree Classifier for {column}: {decision_tree_classifiers[column]}\\n')\n",
        "    from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data[columns_to_classify], data[columns_to_classify].values, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a dictionary to store accuracy scores\n",
        "accuracy_scores = {}\n",
        "\n",
        "for column in columns_to_classify:\n",
        "    # Fit the classifier on the training data\n",
        "    decision_tree_classifiers[column].fit(X_train[[column]], y_train[:, 0])\n",
        "\n",
        "    # Make predictions on the test data\n",
        "    y_pred = decision_tree_classifiers[column].predict(X_test[[column]])\n",
        "\n",
        "    # Calculate the accuracy score\n",
        "    accuracy = accuracy_score(y_test[:, 0], y_pred)\n",
        "\n",
        "    # Store the accuracy score\n",
        "    accuracy_scores[column] = accuracy\n",
        "\n",
        "# Print the accuracy scores\n",
        "for column in columns_to_classify:\n",
        "    print(f'Accuracy - {column}: {accuracy_scores[column]:.2f}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJcE32OkQEfQ",
        "outputId": "fa8434e2-eb0f-40fe-c0a9-f3694eae7f65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column: Final Well-Being Value\n",
            "0       Low\n",
            "1      High\n",
            "2       Low\n",
            "3    Medium\n",
            "4      High\n",
            "Name: Final Well-Being Value Classification, dtype: object\n",
            "Decision Tree Classifier for Final Well-Being Value: DecisionTreeClassifier()\n",
            "\n",
            "Column: Final Sociality Value\n",
            "0     Low\n",
            "1     Low\n",
            "2    High\n",
            "3     Low\n",
            "4    High\n",
            "Name: Final Sociality Value Classification, dtype: object\n",
            "Decision Tree Classifier for Final Sociality Value: DecisionTreeClassifier()\n",
            "\n",
            "Column: Final Emotionality Value\n",
            "0       Low\n",
            "1       Low\n",
            "2    Medium\n",
            "3       Low\n",
            "4      High\n",
            "Name: Final Emotionality Value Classification, dtype: object\n",
            "Decision Tree Classifier for Final Emotionality Value: DecisionTreeClassifier()\n",
            "\n",
            "Column: Final Self-Control Value\n",
            "0     Low\n",
            "1    High\n",
            "2    High\n",
            "3     Low\n",
            "4     Low\n",
            "Name: Final Self-Control Value Classification, dtype: object\n",
            "Decision Tree Classifier for Final Self-Control Value: DecisionTreeClassifier()\n",
            "\n",
            "Accuracy - Final Well-Being Value: 0.00\n",
            "Accuracy - Final Sociality Value: 0.00\n",
            "Accuracy - Final Emotionality Value: 0.00\n",
            "Accuracy - Final Self-Control Value: 0.00\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}